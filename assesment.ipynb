{"cells":[{"cell_type":"markdown","source":["# AI Intern Challenge\n"],"metadata":{"id":"jaikK1N2HO-5"}},{"cell_type":"code","source":["# download all dependendencies, comment out if already installed\n","!pip install vllm\n","!pip install langchain faiss-cpu\n","!pip install -U langchain-community\n","!pip install huggingface_hub\n","!pip install langchain_community\n","!pip install chromadb\n","!pip install langchainhub\n","!pip install beautifulsoup4\n","!pip install requests\n","!pip install python-docx\n","!pip install -U sentence-transformers\n","!pip install unsloth\n","!pip install datasets\n","!pip install peft\n","!pip install transformers>=4.36.0\n","!pip install accelerate>=0.21.0\n","!pip install bitsandbytes>=0.41.0"],"metadata":{"collapsed":true,"id":"_uv9AjT4HVYC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# all imports\n","from unsloth import FastLanguageModel\n","from huggingface_hub import notebook_login\n","import json\n","from typing import Dict\n","from vllm import LLM, SamplingParams\n","import re\n","import requests\n","import time\n","import os\n","from google.colab import drive # comment out if you're not using colab\n","\n","# for Fine-Tuning\n","import pandas as pd\n","from unsloth import FastLanguageModel\n","import torch\n","from datasets import Dataset\n","from peft import AutoPeftModelForCausalLM\n","\n","# For RAG\n","from langchain.docstore.document import Document\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFacePipeline\n","import transformers\n","from concurrent.futures import ThreadPoolExecutor, as_completed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ax6x73RyHNvN","outputId":"178431b2-3fe3-4fd9-8cbb-331eb1cbbdf2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","INFO 04-12 03:05:44 [__init__.py:239] Automatically detected platform cuda.\n"]}]},{"cell_type":"code","source":["# Enter access tokens, remove if saved in secrets\n","notebook_login() # access token for hugging face\n","os.environ['OPENAI_API_KEY'] = 'Your_OpenAI_Key' # your Open AI key"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["c2a20ed3b99346ffa9c6eb3cd68c3997","9fb1cbc4e2fb4d13aa6005485992f10b","7426488d31f94acab057209af4353c39","db756b55b90a48558fb57d44be3d37f2","399c325105cd47d189cccf4783d9f786","27c3c39e09a54fe8b552afc499985afd","120a2365cdac4e8eb4b0cf9a0cb78f8e","b3b57540193c458086be59d696f63777","90c64196215640adbe79e8e9720bd1a3","eaaa8bcd2164412ebaeaf0e85f08c51c","16cb1309b0674bdc8158fb0ec4e5e23f","121b5803f96e43bd847f3656b5c8df9e","4a7cb05397b84d808eee8928cca7dd7d","f75c7fa37806428e8d4b601573682c72","47b67ac0fa6c4c75ac3a689b9b927610","4570a8aaa7884b7e86f0b76508a18845","a0376691e4f8403d936d8c4671ede9e8","ef679091f8f94386b51b266cfc569725","f6373849f26f49758a0e8c4a3f301e28","d1bc5bcae274456ca806463f6a9a5c6b"]},"id":"DQHWda-1YdS7","outputId":"9c06c40f-18ad-4a61-fc21-8b814bb61fa3","executionInfo":{"status":"ok","timestamp":1744501534559,"user_tz":420,"elapsed":16,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2a20ed3b99346ffa9c6eb3cd68c3997"}},"metadata":{}}]},{"cell_type":"code","source":["# Load All Data\n","\n","drive.mount('/content/drive') # comment out if you're not using colab\n","\n","def load_data(file_path: str) -> Dict:\n","    \"\"\"\n","    Load the JSON data from a file.\n","\n","    Args:\n","    file_path (str): Path to the JSON file.\n","\n","    Returns:\n","    Dict: Loaded JSON data.\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","# these variables\n","train_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/train_data.json\"\n","val_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/val_data.json\"\n","\n","train_data = load_data(train_data_filepath)\n","val_data = load_data(val_data_filepath)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a3qJTASJHvk","outputId":"f7f6b20a-ab8f-484d-8fcd-a0625a15659f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa3QCnIm-AEp"},"outputs":[],"source":["# define evaluate_model function\n","\n","def evaluate_model(data: Dict, predictions: Dict) -> float:\n","    \"\"\"\n","    Evaluate the model's performance on a dataset.\n","\n","    Args:\n","    data (Dict): The dataset to evaluate on (can be validation or test set).\n","    predictions (Dict): The model's predictions for the dataset.\n","\n","    Returns:\n","    float: Accuracy of the model.\n","    \"\"\"\n","    correct = 0\n","    total = len(data)\n","\n","    for question_id, question_data in enumerate(data):\n","        if question_id in predictions:\n","            if predictions[question_id] == question_data['answer']:\n","                correct += 1\n","\n","    accuracy = correct / total\n","    return accuracy\n"]},{"cell_type":"markdown","metadata":{"id":"flVTZMNJX1-t"},"source":["## Part A: Basic Inference Engine\n","\n","Usage\n","1. Load the Model\n","2. Define `inference_naive(data, llm, sampling_params)`\n","3. Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":690,"referenced_widgets":["c231d05884dd4448891da109c92a1978","7d04bab9b7a34730b77a0f9b487d56a1","73635c92ad3e4ccb97a441ccbc4fa289","11ae3bac72dc41be943800b7baaec8cb","57ea75c7df4746dd86ff6fced04d3fb9","abbae54eeb754795ad180d9b00ded787","d9981acd226249c48fd812c8a7ef4496","dc0908ebeba7418882158c04c4480f8f","dc7f7ce0e17b4aeca9fe80db8dbcde6f","311388ee80704bb6a52f536d9eda7965","07a8a67bce734e31bc68df3f60f45e2b","6ce6fd96a9894524939791be9b694ffd","e63c2b2dc6d848d5b5500b3b3e231580","db56307a4d6441d29f805cc397e630e3","42b0cfe825f64893aa288f949c679087","c4e1465827fa4805b6d3602a9aaa32ab","dcff5ed94fc84ff4b2b90baf370a04a0","e4213e70f6cb430d95b03b29989a95e8","a58c1ec487e3483ea1ade3c09fc58cf8","98e580fde93f44dbba8392bad90fefad","0b365e257f8e4cc7ba49ee63a6ae548c","b1e14a61012d4a2095aeab4f76cfd9d0","e9ad12bb99eb4e22bb36ceea1384b427","f6452231ee2140de97f51538993f50db","a548bb8dcbf0457cbe1fa0c8f02035bf","160c17a91a944cd8b506305849ed22f5","9f22826c056c4490bbd1e659da06e4be","202582b9e7794ec18634cfd44cc4e98a","dda30b1c6e494607a4d4fea869c59895","12e2a15a2d2c436fb5d5f877656936af","d86d9a3686fe4752b5932242ea3f13d3","7586ac91ca8b4330a855768d39c05899","51c12655f8ea49179348f0e9b7c62a9e","935ac7181ba04da681ea57bdb0728b93","77ead0c16a504ac0bc532a8e0f918e84","c1489a6d153647f997d4a41df4021a48","20fa0c26c2844b3cbfbbfc635865b557","b089056ba32e4e3c8e5d1277b0c022e4","475051f8a52e4f9884a3df46522e2986","d2d9111f88e74cd3a2e5265aac820a5e","af3a46408a634f3f929f7565e8bc3aa9","cf72160633a845cf87098b25f4fa6440","4428a476571340f8b24b94239da541bf","5f93642370c64d98a1cf7add21240cec","a9d7bd86a216496181d9367e1293ec3d","db374ace05344701a9ea4dca361a163d","b01e72ea841b414fb13199d33e230115","44659abb45ab4b159b27dcaade0b22d2","0acf2375d0d840e1bdc15901ad40d839","8a31b1ec251c4b61bb8d5147e099b177","7832711e51654513b43e6a1e54d0d391","c37d45a0c3e24df8b80d4c974cdd491c","66b4a5aa97d14c54b620d93a2f5a9094","8fd07d6ac9474c0f89435f6dfdbf80c6","4cc5c44336e54af5a8e62d031c28b430","3fa7008e51f74f6298815b9ac1ce8d8c","0544b754716f435c8cced9005c824b58","5e1f2328e6b048699490c84824c40f79","a9df74f844f4495e91db3bc72e37d77c","4a87596cf20f4e2199000c04c370fd67","ae31d11bbbd447c887c85393b7bf99ef","c8762824da8247d48144c42ce3edf810","f1d6b769e33745e49abf540d66195e2a","9922cb39f7c24f1a9eba996d88747d42","004c5194d0cc4109a6bfd4635fe53333","0309b9a81fce45a382ad859a1773f67f","92367e10b8f4480ea3783d6a4e8d1712","c1218d3c5b8c4f0b99b8940628fee6c6","6a3c300867cc42c2972e6e2a7b477f8d","be71bec5738f482cb4d6771a3cf065f7","0e0e023fed06488b8cebdd9acfaca824","8552bb965e1341d6ba0af5fdf9b82690","dd28c881d58b4fafae241e76b208bba7","e84d256ab1864e748fae4964209810a0","26117f210199479cac8924c474d6b20d","680742a695f8448bac3b4fbf51e87e08","f41e8de86ff64ba796dc5d5db6327500","5feeb673a91f4892bbae7f6ef8fc5797","a2a0fbdf72af4130afd8fcce081062a2","3e3a66ba312a4567b538ccf6d54728e0","c80348edb6c24a3496777590dd9a5e18","344786bc71e243f4a76923824c57a436","a34feeab6b064d0fb08369f0b5bf80fd","5a430d4c37c8499fbc035b1b561f3d08","ee4bf036be504cafb07f988bd3a9515a","aaf8b00e94d641c18f283a5b04186004","9a604874cf904f0fae11fc2f91b1fdca","eed1a7d9755f47339d1061a762d20a1f","d44bf4153acc4616b5d1504b4fbea656","ba9cabfa912b4ba6a234b82a488fc218","c5477ea326c74df090a784e61fad840a","fd77cb6cb29545f9a2872fb31079862e","11ea231455f84f46801af1a529f2f1f9","7727a6694f8846a1a343c2cb5e23120b","8eaebddecc024b32988878e195194908","07f544fa8eae42a98eb5a51a61f3ce10","b7762ed743be47d8acca23d584f74c9b","a6865447435641ea808e3eca4d0dd878","79a31db2781e42faa8d42026e59a1703"]},"id":"CV5khc2SUfTe","outputId":"460499fb-ddd3-4443-f2ee-b2ab5c8588b8","collapsed":true},"outputs":[{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/878 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c231d05884dd4448891da109c92a1978"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["WARNING 04-10 21:59:18 [config.py:2704] Casting torch.bfloat16 to torch.float16.\n","INFO 04-10 21:59:33 [config.py:600] This model supports multiple tasks: {'generate', 'embed', 'score', 'classify', 'reward'}. Defaulting to 'generate'.\n","WARNING 04-10 21:59:33 [arg_utils.py:1708] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n","INFO 04-10 21:59:33 [llm_engine.py:242] Initializing a V0 LLM engine (v0.8.3) with config: model='meta-llama/Llama-3.2-3B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.2-3B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=4000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Llama-3.2-3B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=None, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":256}, use_cached_outputs=False, \n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ce6fd96a9894524939791be9b694ffd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ad12bb99eb4e22bb36ceea1384b427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"935ac7181ba04da681ea57bdb0728b93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d7bd86a216496181d9367e1293ec3d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 04-10 21:59:36 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n","INFO 04-10 21:59:36 [cuda.py:289] Using XFormers backend.\n","INFO 04-10 21:59:37 [parallel_state.py:957] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n","INFO 04-10 21:59:37 [model_runner.py:1110] Starting to load model meta-llama/Llama-3.2-3B-Instruct...\n","INFO 04-10 21:59:39 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"]},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fa7008e51f74f6298815b9ac1ce8d8c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92367e10b8f4480ea3783d6a4e8d1712"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 04-10 22:02:24 [weight_utils.py:281] Time spent downloading weights for meta-llama/Llama-3.2-3B-Instruct: 165.244036 seconds\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5feeb673a91f4892bbae7f6ef8fc5797"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44bf4153acc4616b5d1504b4fbea656"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["INFO 04-10 22:02:57 [loader.py:447] Loading weights took 31.68 seconds\n","INFO 04-10 22:02:57 [model_runner.py:1146] Model loading took 6.0160 GiB and 199.589262 seconds\n","INFO 04-10 22:03:00 [worker.py:267] Memory profiling takes 2.15 seconds\n","INFO 04-10 22:03:00 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.65) = 9.58GiB\n","INFO 04-10 22:03:00 [worker.py:267] model weights take 6.02GiB; non_torch_memory takes 0.05GiB; PyTorch activation peak memory takes 1.19GiB; the rest of the memory reserved for KV Cache is 2.33GiB.\n","INFO 04-10 22:03:01 [executor_base.py:112] # cuda blocks: 1360, # CPU blocks: 2340\n","INFO 04-10 22:03:01 [executor_base.py:117] Maximum concurrency for 4000 tokens per request: 5.44x\n","INFO 04-10 22:03:06 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"]},{"output_type":"stream","name":"stderr","text":["Capturing CUDA graph shapes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:44<00:00,  1.28s/it]"]},{"output_type":"stream","name":"stdout","text":["INFO 04-10 22:03:51 [model_runner.py:1598] Graph capturing finished in 45 secs, took 0.19 GiB\n","INFO 04-10 22:03:51 [llm_engine.py:448] init engine (profile, create kv cache, warmup model) took 53.64 seconds\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Load the model\n","\n","llm = LLM(\n","    model=\"meta-llama/Llama-3.2-3B-Instruct\",\n","    dtype=\"float16\",\n","    gpu_memory_utilization=0.65,\n","    max_model_len=4000\n",")\n","\n","sampling_params = SamplingParams(temperature=0.01, max_tokens=22)\n"]},{"cell_type":"markdown","source":["### Inference Naive (Prompt Engineering + Experimenting with Sampling Prompts)"],"metadata":{"id":"BMK488MecTfI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"cTZcwCc1UfTe"},"outputs":[],"source":["def inference_naive(data, llm, sampling_params):\n","    \"\"\"\n","    Use Llama 3.2-3B instruct model directly via the vLLM Python API\n","    to answer questions from the TeleQnA dataset.\n","\n","    Args:\n","        data (list): The dataset (list of question dicts).\n","        llm (vllm.LLM): An already-instantiated LLM object from vLLM.\n","        sampling_params (vllm.SamplingParams): Parameters for generation.\n","\n","    Returns:\n","        Dict[int, str]: A dictionary mapping question_id to predicted answer.\n","    \"\"\"\n","\n","    # Prepare prompts for all questions\n","    prompts = []\n","    question_ids = []\n","\n","    print(f\"Preparing prompts for {len(data)} questions...\")\n","\n","    for question_id, question_data in enumerate(data):\n","        # Build a prompt for each question with all its options.\n","        prompt = (\n","            \"Answer the following multiple-choice question about telecommunications. \"\n","            \"Only respond with exactly one option (e.g., 'option 1', 'option 2', etc.) \"\n","            \"without any additional text.\\n\\n\"\n","            \"Example 1:\\n\"\n","            \"Question: What is the capital of France?\\n\"\n","            \"option 1: Berlin\\n\"\n","            \"option 2: Madrid\\n\"\n","            \"option 3: Paris\\n\"\n","            \"option 4: Rome\\n\"\n","            \"option 5: Oslo\\n\"\n","            \"Answer: option 3\\n\\n\"\n","            \"Example 2:\\n\"\n","            \"Question: What does HTTPS stand for?\\n\"\n","            \"option 1: Hypertext Transfer Protocol Secure\\n\"\n","            \"option 2: Hypertext Transfer Protocol Standard\\n\"\n","            \"option 3: Hypertext Transfer Protocol System\\n\"\n","            \"option 4: Hypertext Transfer Protocol Specification\\n\"\n","            \"option 5: Hypertext Transfer Protocol\\n\"\n","            \"Answer: option 1\\n\\n\"\n","            f\"Now, answer the question below in the same format:\\n\"\n","            f\"Question: {question_data['question']}\\n\"\n","        )\n","\n","        # Add all available options\n","        for option_key in sorted(k for k in question_data if k.startswith(\"option \")):\n","            prompt += f\"{option_key}: {question_data[option_key]}\\n\"\n","\n","        prompt += \"\\nAnswer: \"\n","\n","        prompts.append(prompt)\n","        question_ids.append(question_id)\n","\n","    # Process in batches for efficiency\n","    batch_size = 32\n","    predictions = {}\n","\n","    print(f\"Running inference in batches of {batch_size}...\")\n","    for i in range(0, len(prompts), batch_size):\n","        batch_prompts = prompts[i : i + batch_size]\n","        batch_ids = question_ids[i : i + batch_size]\n","        print(f\"Processing batch {i//batch_size + 1}/{(len(prompts) + batch_size - 1)//batch_size}\")\n","\n","        # Generate with vLLM\n","        outputs = llm.generate(\n","                            prompts=batch_prompts,\n","                            sampling_params=sampling_params  # crucial keyword\n","                        )\n","        # Process the outputs\n","        for output, q_id in zip(outputs, batch_ids):\n","            # Get generated text\n","            generated_text = output.outputs[0].text.strip().lower() if output.outputs else \"\"\n","\n","            # Try to match using regex to capture both \"option\" and just a digit\n","            match = re.search(r\"option\\s*(\\d)\", generated_text)\n","            if not match:\n","                # If no \"option\" found, check if there's just a standalone digit\n","                match = re.search(r\"^\\D*(\\d)\\D*$\", generated_text)\n","\n","            if match:\n","                option_number = match.group(1)\n","                predictions[q_id] = f\"option {option_number}\"\n","            else:\n","                predictions[q_id] = \"option 1\"  # default fallback\n","\n","\n","    print(f\"Inference completed for {len(predictions)} questions.\")\n","    return predictions\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ei1QUeJ5UfTf","outputId":"20961e8c-e9cb-4ec2-cf02-881f6a828d53"},"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing prompts for 2000 questions...\n","Running inference in batches of 32...\n","Processing batch 1/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.89it/s, est. speed input: 2939.89 toks/s, output: 27.53 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 2/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.99it/s, est. speed input: 2962.82 toks/s, output: 32.98 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 3/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.14it/s, est. speed input: 2966.94 toks/s, output: 32.26 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 4/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.57it/s, est. speed input: 2641.01 toks/s, output: 31.39 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 5/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.75it/s, est. speed input: 2590.41 toks/s, output: 38.97 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 6/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.20it/s, est. speed input: 3017.25 toks/s, output: 33.59 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 7/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.05it/s, est. speed input: 2554.18 toks/s, output: 35.16 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 8/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.81it/s, est. speed input: 3087.99 toks/s, output: 29.23 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 9/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.13it/s, est. speed input: 2470.35 toks/s, output: 36.10 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 10/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.98it/s, est. speed input: 2961.11 toks/s, output: 26.96 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 11/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.17it/s, est. speed input: 2485.67 toks/s, output: 34.97 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 12/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.94it/s, est. speed input: 2458.79 toks/s, output: 30.74 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 13/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.04it/s, est. speed input: 2988.78 toks/s, output: 27.46 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 14/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.52it/s, est. speed input: 2518.48 toks/s, output: 37.81 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 15/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.27it/s, est. speed input: 2514.54 toks/s, output: 36.61 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 16/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 13.04it/s, est. speed input: 3173.18 toks/s, output: 29.34 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 17/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.99it/s, est. speed input: 3023.84 toks/s, output: 29.24 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 18/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.31it/s, est. speed input: 2576.89 toks/s, output: 32.55 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 19/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.47it/s, est. speed input: 3164.63 toks/s, output: 29.61 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 20/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.53it/s, est. speed input: 2558.91 toks/s, output: 34.24 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 21/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.44it/s, est. speed input: 3053.13 toks/s, output: 32.26 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 22/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.66it/s, est. speed input: 2625.63 toks/s, output: 37.29 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 23/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 3252.86 toks/s, output: 28.90 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 24/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.36it/s, est. speed input: 2981.35 toks/s, output: 30.93 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 25/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.72it/s, est. speed input: 3017.48 toks/s, output: 32.99 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 26/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.56it/s, est. speed input: 2610.43 toks/s, output: 34.66 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 27/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.44it/s, est. speed input: 2609.05 toks/s, output: 42.40 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 28/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.84it/s, est. speed input: 3153.82 toks/s, output: 29.69 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 29/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.56it/s, est. speed input: 2560.76 toks/s, output: 38.94 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 30/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.90it/s, est. speed input: 2694.15 toks/s, output: 39.87 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 31/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.88it/s, est. speed input: 2695.66 toks/s, output: 38.44 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 32/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.72it/s, est. speed input: 2598.82 toks/s, output: 39.21 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 33/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.35it/s, est. speed input: 2549.48 toks/s, output: 37.84 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 34/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 13.04it/s, est. speed input: 3133.46 toks/s, output: 30.16 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 35/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.41it/s, est. speed input: 2848.06 toks/s, output: 29.25 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 36/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.74it/s, est. speed input: 2580.59 toks/s, output: 33.90 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 37/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.29it/s, est. speed input: 3033.44 toks/s, output: 29.96 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 38/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.65it/s, est. speed input: 2561.27 toks/s, output: 29.99 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 39/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.76it/s, est. speed input: 2650.99 toks/s, output: 37.31 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 40/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.29it/s, est. speed input: 2524.90 toks/s, output: 35.69 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 41/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.50it/s, est. speed input: 3064.98 toks/s, output: 29.69 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 42/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.69it/s, est. speed input: 2588.36 toks/s, output: 34.08 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 43/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.65it/s, est. speed input: 3088.97 toks/s, output: 30.44 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 44/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.94it/s, est. speed input: 2506.15 toks/s, output: 36.65 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 45/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.39it/s, est. speed input: 2610.74 toks/s, output: 32.16 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 46/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 10.72it/s, est. speed input: 2591.30 toks/s, output: 37.54 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 47/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00,  9.96it/s, est. speed input: 2531.02 toks/s, output: 37.97 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 48/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.94it/s, est. speed input: 3095.63 toks/s, output: 31.15 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 49/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.58it/s, est. speed input: 3168.47 toks/s, output: 28.30 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 50/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.24it/s, est. speed input: 2538.45 toks/s, output: 32.96 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 51/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.43it/s, est. speed input: 2625.77 toks/s, output: 37.15 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 52/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.30it/s, est. speed input: 2579.91 toks/s, output: 44.11 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 53/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.43it/s, est. speed input: 2564.29 toks/s, output: 36.83 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 54/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.31it/s, est. speed input: 3117.15 toks/s, output: 30.78 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 55/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.95it/s, est. speed input: 3172.65 toks/s, output: 29.95 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 56/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 11.59it/s, est. speed input: 2804.89 toks/s, output: 33.73 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 57/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.61it/s, est. speed input: 2611.82 toks/s, output: 34.82 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 58/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.78it/s, est. speed input: 3090.36 toks/s, output: 32.35 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 59/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.46it/s, est. speed input: 2543.85 toks/s, output: 36.61 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 60/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.45it/s, est. speed input: 2584.50 toks/s, output: 31.38 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 61/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:03<00:00, 10.54it/s, est. speed input: 2642.44 toks/s, output: 30.30 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 62/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32/32 [00:02<00:00, 12.18it/s, est. speed input: 2993.31 toks/s, output: 32.76 toks/s]\n"]},{"output_type":"stream","name":"stdout","text":["Processing batch 63/63\n"]},{"output_type":"stream","name":"stderr","text":["Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:01<00:00, 11.47it/s, est. speed input: 2837.04 toks/s, output: 30.15 toks/s]"]},{"output_type":"stream","name":"stdout","text":["Inference completed for 2000 questions.\n","Inference took 180.6603980064392 seconds.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["start = time.time()\n","predictions = inference_naive(val_data, llm, sampling_params)\n","end = time.time()\n","print(f\"Inference took {end - start} seconds.\")\n","runtime_naive = end - start"]},{"cell_type":"code","source":["# Evaluate the predictions\n","accuracy = evaluate_model(val_data, predictions)\n","print(f\"Model accuracy: {accuracy * 100:.2f}%\")\n","print(f\"Inference took {runtime_naive} seconds.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jdN4VlNFzSTt","outputId":"eda5bac0-16e3-4e63-abef-beaa35a5780f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model accuracy: 63.05%\n","Inference took 180.6603980064392 seconds.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Gd8QMEq2YCLo"},"source":["## Part B: Fine-Tuning the LLM\n","\n","Instructions to Run:\n","1. **Restart Session** to free up System RAM\n","2. Import dependencies\n","3. Load data\n","4. Train model (alter parameters, if required)\n","5. Restart Session again as notebook environments like Colab or Jupyter the state can become inconsistent during a long session.\n","6. Define `inference_fine_tuned(data, model_path, batch_size=32)`\n","7. Evaluate Checkpoints and choose the best model"]},{"cell_type":"code","source":["# all imports\n","from unsloth import FastLanguageModel\n","from datasets import Dataset\n","import json\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer\n","from trl import SFTTrainer\n","import re\n","from google.colab import drive # comment out if you're not using colab\n","\n","from huggingface_hub import notebook_login\n","from typing import Dict\n","from vllm import LLM, SamplingParams\n","import time\n","import os\n","import torch\n","from peft import AutoPeftModelForCausalLM\n","import gc\n","\n","# For RAG\n","from langchain.docstore.document import Document\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFacePipeline\n","import transformers\n","from concurrent.futures import ThreadPoolExecutor, as_completed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EC0qR9fudH2P","outputId":"c2320d95-c00c-4947-b940-07b2af057b5d","executionInfo":{"status":"ok","timestamp":1744518119850,"user_tz":420,"elapsed":53402,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-30b311ced9a6>:10: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth import FastLanguageModel\n"]},{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","INFO 04-13 04:21:43 [__init__.py:239] Automatically detected platform cuda.\n"]}]},{"cell_type":"code","source":["# Load All Data\n","\n","drive.mount('/content/drive') # comment out if you're not using colab\n","\n","def load_data(file_path: str) -> Dict:\n","    \"\"\"\n","    Load the JSON data from a file.\n","\n","    Args:\n","    file_path (str): Path to the JSON file.\n","\n","    Returns:\n","    Dict: Loaded JSON data.\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","# these variables\n","train_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/train_data.json\"\n","val_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/val_data.json\"\n","\n","train_data = load_data(train_data_filepath)\n","val_data = load_data(val_data_filepath)\n","results = load_data(\"/content/drive/MyDrive/airaChallenge/results.json\")\n","\n","# define evaluate_model function\n","\n","def evaluate_model(data: Dict, predictions: Dict) -> float:\n","    \"\"\"\n","    Evaluate the model's performance on a dataset.\n","\n","    Args:\n","    data (Dict): The dataset to evaluate on (can be validation or test set).\n","    predictions (Dict): The model's predictions for the dataset.\n","\n","    Returns:\n","    float: Accuracy of the model.\n","    \"\"\"\n","    correct = 0\n","    total = len(data)\n","\n","    for question_id, question_data in enumerate(data):\n","        if question_id in predictions:\n","            if predictions[question_id] == question_data['answer']:\n","                correct += 1\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n"],"metadata":{"id":"01vhQmHraLEg","colab":{"base_uri":"https://localhost:8080/"},"outputId":"68882acd-72d3-4177-c115-3c4577a24952","executionInfo":{"status":"ok","timestamp":1744518120621,"user_tz":420,"elapsed":750,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["\n","def prepare_dataset_for_finetuning(data):\n","    \"\"\"Convert TeleQnA data into instruction format for fine-tuning\"\"\"\n","    formatted_data = []\n","\n","    for item in data:\n","        # Create prompt with question and options\n","        question = item['question']\n","        options_text = \"\"\n","        for option_key in sorted(k for k in item if k.startswith(\"option \")):\n","            options_text += f\"{option_key}: {item[option_key]}\\n\"\n","\n","        prompt = f\"You're a telemcommunications expert. Here's a multiple-choice question about telecommunications' {item['category'].lower() if item['category'] else ''}. Consider technical details carefully. Only respond with exactly one option without additional text.\\n\\nQuestion: {question}\\n{options_text}\"\n","\n","        # The completion is just the answer option\n","        completion = item['answer']\n","\n","        formatted_data.append({\n","            \"text\": f\"<s>[INST] {prompt} [/INST] {completion} </s>\"\n","        })\n","\n","\n","\n","    return  Dataset.from_pandas(pd.DataFrame(formatted_data))"],"metadata":{"id":"lGusXLEddGE7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","train_dataset = prepare_dataset_for_finetuning(train_data)\n","val_dataset = prepare_dataset_for_finetuning(val_data)"],"metadata":{"id":"hYna2ibNdW4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name=\"meta-llama/Llama-3.2-3B-Instruct\",\n","    max_seq_length=2048,\n","    dtype=torch.float16,\n","    load_in_4bit=True,  # Use 4-bit quantization to fit on T4\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfEXiLQDdXB4","outputId":"249f58be-d0cd-4e43-be90-4b5874e5c562","executionInfo":{"status":"ok","timestamp":1744518136752,"user_tz":420,"elapsed":15618,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.2. vLLM: 0.8.3.\n","   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n","O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n","\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n"," \"-____-\"     Free license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}]},{"cell_type":"code","source":["# Add LoRA adapters for efficient fine-tuning\n","model = FastLanguageModel.get_peft_model(\n","    model,\n","    r=32,              # Rank\n","    lora_alpha=64,     # Alpha parameter for LoRA\n","    lora_dropout=0.05,  # Dropout probability for LoRA\n","    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x54Paj9qditw","outputId":"23a0db3c-39f4-4264-f73e-6d1961dd9382","executionInfo":{"status":"ok","timestamp":1744518140901,"user_tz":420,"elapsed":4157,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.\n","Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.\n","Unsloth 2025.3.19 patched 28 layers with 0 QKV layers, 0 O layers and 0 MLP layers.\n"]}]},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir=\"./telecom_finetuned\",\n","    # Instead of setting num_train_epochs=6, set max_steps directly\n","    max_steps=800,\n","    per_device_train_batch_size=4,\n","    gradient_accumulation_steps=4,\n","    learning_rate=2e-4,\n","    warmup_ratio=0.05,\n","    lr_scheduler_type=\"cosine\",\n","    logging_steps=25,\n","    save_strategy=\"steps\",\n","    save_steps=50,                # Save more frequently to find the optimal point\n","    optim=\"adamw_torch\",\n","    fp16=True,\n","    bf16=False,\n","    weight_decay=0.01,\n",")"],"metadata":{"id":"t-KTeU8DdwVI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = SFTTrainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=train_dataset,\n","    args=training_args,\n",")\n","os.environ['UNSLOTH_RETURN_LOGITS'] = '1'\n","trainer.train()\n","end = time.time()\n","print(f\"Training took {end - start} seconds.\")\n","fine_tuning_train_time = end - start"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f5518389e9654da7937dba7e4531e699","2fad272eb1024e0596b9ad7421727aa4","ee4262acbb294dcfa8f7b15b21388d91","09db201301984f8fa24ab0477588cc0d","b37a4d2d5cf14fc4becbea735e171fa6","6d72002bac1f42dcba8fa738ff9e7882","18ded8b4b5484a64876e2a2def7b2fce","4db2baa2a09e451e8895f9d2b5756b03","85c3c074cf1641b1960bbde67bf8c3e4","b76458de4ed74bf7a71de5650085311d","388cff1130844d3cbb3cda1cca752d80","09b3202b094742c59403cf75dac3646a","94e0aeeb45a34960b059032a133c26db","79f0734c755e43afb2efb63d63afc3c2","496bf490032649fbba31596805954d71","30eed52c15504319a7d37614e5d7f4c3","fa50bf91414d45c5a685282bfb602003","452ddf2fb25b4094a36515873792f201","c85e6d10601f4864a17a026274da74fd","1be71da38d9b473583c3b3ed3fafaebf","4391015177e54ebc81d30618dfd48f33","d14650774b7c488d893732b06f107c9b","05e45988d5c74d6e8ebf4b144bac9931","ceb69a1593ca49b99f95ca50c7d40bda","85efe3f237e94b409b78604a70ce97b0","bafd32ec9d944a0ebc869a29d4e10377","d664cc6582f5419ba98f1f1a63d55608","46861028e68447258096b5e72042b871","ed51a329b72c492aa69ad7dca4200aa7","fa077d1d8a6b40428eae645ad074b917","9a71ede9afff45a9b139845652ae6e34","9c252e20995347d9aebcef1fe1430714","98ba359f572245e6b57ab6554fe248c6"]},"id":"BL0vUqJTd_FJ","outputId":"ef36c5bc-ef64-4602-b27e-833e8929b53f","executionInfo":{"status":"ok","timestamp":1744521360871,"user_tz":420,"elapsed":3219955,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-fd88de9c8b6a>:1: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n","  trainer = SFTTrainer(\n"]},{"output_type":"display_data","data":{"text/plain":["Converting train dataset to ChatML (num_proc=2):   0%|          | 0/6000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5518389e9654da7937dba7e4531e699"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying chat template to train dataset (num_proc=2):   0%|          | 0/6000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09b3202b094742c59403cf75dac3646a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Tokenizing train dataset (num_proc=2):   0%|          | 0/6000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05e45988d5c74d6e8ebf4b144bac9931"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n","   \\\\   /|    Num examples = 6,000 | Num Epochs = 3 | Total steps = 800\n","O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n","\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n"," \"-____-\"     Trainable parameters = 48,627,712/3,000,000,000 (1.62% trained)\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mshreyasudan2211\u001b[0m (\u001b[33mshreyasudan2211-university-of-california\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.19.9"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250413_042233-qk6qej5o</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/shreyasudan2211-university-of-california/huggingface/runs/qk6qej5o' target=\"_blank\">./telecom_finetuned</a></strong> to <a href='https://wandb.ai/shreyasudan2211-university-of-california/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/shreyasudan2211-university-of-california/huggingface' target=\"_blank\">https://wandb.ai/shreyasudan2211-university-of-california/huggingface</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/shreyasudan2211-university-of-california/huggingface/runs/qk6qej5o' target=\"_blank\">https://wandb.ai/shreyasudan2211-university-of-california/huggingface/runs/qk6qej5o</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Unsloth: Will smartly offload gradients to save VRAM!\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='800' max='800' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [800/800 53:19, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>2.033600</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>1.060700</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>1.036800</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>1.006700</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>0.994400</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.984000</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>0.974900</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.974500</td>\n","    </tr>\n","    <tr>\n","      <td>225</td>\n","      <td>0.967400</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.973200</td>\n","    </tr>\n","    <tr>\n","      <td>275</td>\n","      <td>0.982200</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.962500</td>\n","    </tr>\n","    <tr>\n","      <td>325</td>\n","      <td>0.959300</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.933200</td>\n","    </tr>\n","    <tr>\n","      <td>375</td>\n","      <td>0.950800</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.807800</td>\n","    </tr>\n","    <tr>\n","      <td>425</td>\n","      <td>0.797000</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.783800</td>\n","    </tr>\n","    <tr>\n","      <td>475</td>\n","      <td>0.779900</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.792400</td>\n","    </tr>\n","    <tr>\n","      <td>525</td>\n","      <td>0.778800</td>\n","    </tr>\n","    <tr>\n","      <td>550</td>\n","      <td>0.766200</td>\n","    </tr>\n","    <tr>\n","      <td>575</td>\n","      <td>0.793000</td>\n","    </tr>\n","    <tr>\n","      <td>600</td>\n","      <td>0.777100</td>\n","    </tr>\n","    <tr>\n","      <td>625</td>\n","      <td>0.757200</td>\n","    </tr>\n","    <tr>\n","      <td>650</td>\n","      <td>0.765700</td>\n","    </tr>\n","    <tr>\n","      <td>675</td>\n","      <td>0.799200</td>\n","    </tr>\n","    <tr>\n","      <td>700</td>\n","      <td>0.770600</td>\n","    </tr>\n","    <tr>\n","      <td>725</td>\n","      <td>0.771500</td>\n","    </tr>\n","    <tr>\n","      <td>750</td>\n","      <td>0.735300</td>\n","    </tr>\n","    <tr>\n","      <td>775</td>\n","      <td>0.653300</td>\n","    </tr>\n","    <tr>\n","      <td>800</td>\n","      <td>0.668500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Training took 3240.2419049739838 seconds.\n"]}]},{"cell_type":"markdown","source":["ðŸš¨**STOP: Restart the Session**ðŸš¨\n","\n","To avoid memory leaks from previous model loads, likely a runtime environment issue, restart the notebook. This happens sometimes in notebook environments like Colab or Jupyter where the state can become inconsistent during a long session.\n","\n"],"metadata":{"id":"yVDGft6G6vXz"}},{"cell_type":"code","source":["# all imports\n","from unsloth import FastLanguageModel\n","from datasets import Dataset\n","import json\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer, AutoTokenizer\n","from trl import SFTTrainer\n","import re\n","from google.colab import drive # comment out if you're not using colab\n","\n","from huggingface_hub import notebook_login\n","from typing import Dict\n","from vllm import LLM, SamplingParams\n","import time\n","import os\n","import torch\n","from peft import AutoPeftModelForCausalLM\n","\n","# For RAG\n","from langchain.docstore.document import Document\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFacePipeline\n","import transformers\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","# Load All Data\n","\n","drive.mount('/content/drive') # comment out if you're not using colab\n","\n","def load_data(file_path: str) -> Dict:\n","    \"\"\"\n","    Load the JSON data from a file.\n","\n","    Args:\n","    file_path (str): Path to the JSON file.\n","\n","    Returns:\n","    Dict: Loaded JSON data.\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","# these variables\n","train_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/train_data.json\"\n","val_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/val_data.json\"\n","\n","train_data = load_data(train_data_filepath)\n","val_data = load_data(val_data_filepath)\n","\n","# define evaluate_model function\n","\n","def evaluate_model(data: Dict, predictions: Dict) -> float:\n","    \"\"\"\n","    Evaluate the model's performance on a dataset.\n","\n","    Args:\n","    data (Dict): The dataset to evaluate on (can be validation or test set).\n","    predictions (Dict): The model's predictions for the dataset.\n","\n","    Returns:\n","    float: Accuracy of the model.\n","    \"\"\"\n","    incorrect = {}\n","    correct = 0\n","    total = len(data)\n","\n","    for question_id, question_data in enumerate(data):\n","        if question_id in predictions:\n","            if predictions[question_id] == question_data['answer']:\n","                correct += 1\n","            # else:\n","              # print(f\"Incorrect: {question_data['question']}\")\n","              # print(f\"Correct answer: {question_data['category']}\")\n","\n","    accuracy = correct / total\n","    return accuracy\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cbzsR6nd6s2F","outputId":"5064ea5e-8b94-4113-fc6c-1cb2f66b93d1","executionInfo":{"status":"ok","timestamp":1744534178012,"user_tz":420,"elapsed":40819,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-1-3b1cb38a9c14>:10: UserWarning: WARNING: Unsloth should be imported before trl, transformers, peft to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth import FastLanguageModel\n"]},{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","INFO 04-13 08:49:28 [__init__.py:239] Automatically detected platform cuda.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["def inference_fine_tuned(data, model_path, batch_size=32):\n","    \"\"\"Use fine-tuned model with batching for faster inference\"\"\"\n","\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        model_path,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","    )\n","\n","    predictions = {}\n","\n","    # Process in batches\n","    for i in range(0, len(data), batch_size):\n","        batch_data = data[i:i+batch_size]\n","        batch_prompts = []\n","        batch_ids = []\n","\n","        for question_id, question_data in enumerate(batch_data, start=i):\n","            question = question_data['question']\n","            options_text = \"\"\n","            for option_key in sorted(k for k in question_data if k.startswith(\"option \")):\n","                options_text += f\"{option_key}: {question_data[option_key]}\\n\"\n","\n","            prompt = f\"\"\"You're a telemcommunications expert. Here's a multiple-choice question about telecommunications' {question_data['category'].lower() if question_data['category'] else ''}. Consider technical details carefully. Only respond with exactly one option without additional text, for example,\n","\n","Example:\n","Question: What does HTTPS stand for?\n","option 1: Hypertext Transfer Protocol Secure\n","option 2: Hypertext Transfer Protocol Standard\n","option 3: Hypertext Transfer Protocol System\n","option 4: Hypertext Transfer Protocol Specification\n","option 5: Hypertext Transfer Protocol\n","Answer: option 1\n","\n","Now, answer the question below in the same format:\n","Question: {question}\n","{options_text}[/INST]\"\"\"\n","\n","            batch_prompts.append(prompt)\n","            batch_ids.append(question_id)\n","\n","        # Tokenize batch\n","        inputs = tokenizer(batch_prompts, padding=True, padding_side='left', return_tensors=\"pt\").to(model.device)\n","\n","        # Generate for whole batch\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids=inputs.input_ids,\n","                attention_mask=inputs.attention_mask,\n","                max_new_tokens=20,\n","                temperature=0.01,\n","                do_sample=False\n","            )\n","\n","        # Process batch outputs\n","        for output, q_id, prompt in zip(outputs, batch_ids, batch_prompts):\n","            generated_text = tokenizer.decode(output, skip_special_tokens=True)\n","\n","            # Remove the prompt from the generated text\n","            if prompt in generated_text:\n","                generated_text = generated_text[len(prompt):].strip().lower()\n","            else:\n","                generated_text = generated_text.strip().lower()\n","\n","            # Extract answer\n","            match = re.search(r\"option\\s*(\\d)\", generated_text)\n","            if not match:\n","                match = re.search(r\"^\\D*(\\d)\\D*$\", generated_text)\n","\n","            if match:\n","                option_number = match.group(1)\n","                predictions[q_id] = f\"option {option_number}\"\n","            else:\n","                predictions[q_id] = \"option 1\"  # default fallback\n","\n","    return predictions"],"metadata":{"id":"pbnJpsryT3ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def evaluate_all_checkpoints(checkpoints, val_data):\n","    results = {}\n","\n","    for ckpt in checkpoints:\n","        start = time.time()\n","        # Run inference and evaluation\n","        predictions = inference_fine_tuned(val_data, ckpt)\n","        end = time.time()\n","        print(f\"Inference took {end - start} seconds.\")\n","        runtime_batch = end - start\n","        accuracy = evaluate_model(val_data, predictions)\n","\n","        results[ckpt] = {'accuracy' : accuracy, 'time' : runtime_batch}\n","        print(f\"Checkpoint {ckpt}: accuracy = {accuracy * 100:.2f}%\")\n","\n","    return results"],"metadata":{"id":"cqASavKtFvG2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test each checkpoint\n","checkpoints = [\n","    \"/content/telecom_finetuned/checkpoint-400\",\n","    \"/content/telecom_finetuned/checkpoint-500\",\n","    \"/content/telecom_finetuned/checkpoint-600\",\n","    \"/content/telecom_finetuned/checkpoint-700\",\n","    \"/content/telecom_finetuned/checkpoint-800\",\n","]\n","\n","evaluate_all_checkpoints(checkpoints, val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haWkESq0AfID","executionInfo":{"status":"ok","timestamp":1744530260339,"user_tz":420,"elapsed":8285288,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}},"outputId":"f3358cc4-d4ae-4573-c18a-564571e87d13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference took 1663.2670772075653 seconds.\n","Checkpoint /content/telecom_finetuned/checkpoint-400: accuracy = 68.65%\n","Inference took 1654.464478969574 seconds.\n","Checkpoint /content/telecom_finetuned/checkpoint-500: accuracy = 70.30%\n","Inference took 1653.3009474277496 seconds.\n","Checkpoint /content/telecom_finetuned/checkpoint-600: accuracy = 69.05%\n","Inference took 1655.3874034881592 seconds.\n","Checkpoint /content/telecom_finetuned/checkpoint-700: accuracy = 69.25%\n","Inference took 1658.7776672840118 seconds.\n","Checkpoint /content/telecom_finetuned/checkpoint-800: accuracy = 69.40%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'/content/telecom_finetuned/checkpoint-400': {'accuracy': 0.6865,\n","  'time': 1663.2670772075653},\n"," '/content/telecom_finetuned/checkpoint-500': {'accuracy': 0.703,\n","  'time': 1654.464478969574},\n"," '/content/telecom_finetuned/checkpoint-600': {'accuracy': 0.6905,\n","  'time': 1653.3009474277496},\n"," '/content/telecom_finetuned/checkpoint-700': {'accuracy': 0.6925,\n","  'time': 1655.3874034881592},\n"," '/content/telecom_finetuned/checkpoint-800': {'accuracy': 0.694,\n","  'time': 1658.7776672840118}}"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# Test each checkpoint\n","checkpoints = [\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-100\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-150\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-200\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-250\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-300\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-350\",\n","    \"/content/telecom_finetuned_model_increased_epochs/checkpoint-400\",\n","]\n","\n","evaluate_all_checkpoints(checkpoints, val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MG_T4qtUahfx","outputId":"f18e66b3-86b9-4141-de52-04eb1b7a7d5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Checkpoint /content/telecom_finetuned_model/checkpoint-100: accuracy = 68.90%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-150: accuracy = 68.75%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-200: accuracy = 70.30%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-250: accuracy = 69.85%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-300: accuracy = 70.90%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-350: accuracy = 71.10%\n","Checkpoint /content/telecom_finetuned_model/checkpoint-400: accuracy = 71.25%\n"]}]},{"cell_type":"code","source":["# Pick the best model, this may differ for your run\n","best_model = \"/content/telecom_finetuned/checkpoint-400\""],"metadata":{"id":"3Rhf35sSJ9QR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","predictions = inference_fine_tuned(val_data, best_model)\n","end = time.time()\n","print(f\"Inference took {end - start} seconds.\")\n","runtime_batch = end - start\n","accuracy = evaluate_model(val_data, predictions)\n","print(f\"Model accuracy: {accuracy * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7um4FbzJWuJz","outputId":"0da4057c-bebe-4b30-e3a4-f722e33b527f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Inference took 1248.202805519104 seconds.\n","Model accuracy: 72.25%\n"]}]},{"cell_type":"markdown","source":["### Appendix: RAG Implementation on the Fine-Tuned Model\n","\n","1. Let's restart the session to free up our GPU and RAM\n","2. Import dependencies\n","3. Set up your OpenAI API Key\n","4. Extract information from the Wireless Documents [3GPP](https://www.3gpp.org/ftp/Specs/archive/38_series/38.201/) after storing the files locally\n","5. Extract information from training dataset\n","6. Prepare the documents into chunks\n","7. Create a vectore store\n","8. Run `inference_with_rag`"],"metadata":{"id":"kwFMSokLugAi"}},{"cell_type":"code","source":["from unsloth import FastLanguageModel\n","import os\n","import re\n","import json\n","import numpy as np\n","import requests\n","from bs4 import BeautifulSoup\n","from tqdm import tqdm\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.embeddings import HuggingFaceEmbeddings, OpenAIEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain.schema import Document\n","import torch\n","from sentence_transformers import SentenceTransformer\n","from sentence_transformers.util import cos_sim\n","from google.colab import drive\n","\n","# all imports\n","from datasets import Dataset\n","import pandas as pd\n","from transformers import TrainingArguments, Trainer\n","from trl import SFTTrainer\n","from google.colab import drive # comment out if you're not using colab\n","\n","from huggingface_hub import notebook_login\n","from typing import Dict\n","from vllm import LLM, SamplingParams\n","import time\n","import os\n","import torch\n","from peft import AutoPeftModelForCausalLM\n","\n","# For RAG\n","from langchain.docstore.document import Document\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n","from langchain.chains import RetrievalQA\n","from langchain.llms import HuggingFacePipeline\n","import transformers\n","from concurrent.futures import ThreadPoolExecutor, as_completed\n","\n","# Load All Data\n","\n","drive.mount('/content/drive') # comment out if you're not using colab\n","\n","def load_data(file_path: str) -> Dict:\n","    \"\"\"\n","    Load the JSON data from a file.\n","\n","    Args:\n","    file_path (str): Path to the JSON file.\n","\n","    Returns:\n","    Dict: Loaded JSON data.\n","    \"\"\"\n","    with open(file_path, 'r') as file:\n","        data = json.load(file)\n","    return data\n","\n","# these variables\n","train_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/train_data.json\"\n","val_data_filepath = \"/content/drive/MyDrive/airaChallenge/data/val_data.json\"\n","\n","train_data = load_data(train_data_filepath)\n","val_data = load_data(val_data_filepath)\n","results = load_data(\"/content/drive/MyDrive/airaChallenge/results.json\")\n","\n","# define evaluate_model function\n","\n","def evaluate_model(data: Dict, predictions: Dict) -> float:\n","    \"\"\"\n","    Evaluate the model's performance on a dataset.\n","\n","    Args:\n","    data (Dict): The dataset to evaluate on (can be validation or test set).\n","    predictions (Dict): The model's predictions for the dataset.\n","\n","    Returns:\n","    float: Accuracy of the model.\n","    \"\"\"\n","    correct = 0\n","    total = len(data)\n","\n","    for question_id, question_data in enumerate(data):\n","        if question_id in predictions:\n","            if predictions[question_id] == question_data['answer']:\n","                correct += 1\n","\n","    accuracy = correct / total\n","    return accuracy\n","\n","# Enter access tokens, remove if saved in secrets\n","notebook_login() # access token for hugging face\n","os.environ['OPENAI_API_KEY'] = 'Your_OpenAI_Key' # your Open AI key"],"metadata":{"id":"wn8XeHpRuoNz","colab":{"base_uri":"https://localhost:8080/","height":104,"referenced_widgets":["8bd9658450284addaf830625f0ef5a99","ec5a9c52ebed44d19c4768bc993d235b","7d981d02638f45cfb9279c6efacab2c1","66005074b14a4f7bb56212116da60b53","cff375b4bed3483c8c6f0926f5b46d92","5dff4f6edde34097ad16a42ee4b1c974","3e1499e4de7144a9a003f1595c29558c","452be979cea943df8003074fb2cfd05d","7b74ccbe5bcb43469107da64123735a3","348c76d990c34700806e11a99718cd43","5bba2e6a80ea4ef2b0bb119a9984681e","7c7810cf168342beb217cdf184e2a8ac","3d51d1a97f804c2f8521d8602c023555","14d738b7e0c048b68f80b8db380784ea","4c8345a67d144a648b2cfe7fcff38825","6e3f0014ed4548beb2abc2ed08355896","36c568fec7ac4de9ba5e59c2fc02ebbc","05ded2dc455d481586976aaf9394c2c5","3ae97b9ec18e4349b6e810de752cd173","e66e6b9b55de4db88177c43609fcddaa"]},"outputId":"3b372ea6-fa3a-4929-a1eb-5beba4cc0aaa","executionInfo":{"status":"ok","timestamp":1744535061155,"user_tz":420,"elapsed":41777,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n","ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n","INFO 04-13 09:04:08 [__init__.py:239] Automatically detected platform cuda.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bd9658450284addaf830625f0ef5a99"}},"metadata":{}}]},{"cell_type":"code","source":["# 1. Reading the Wireless Documents at https://www.3gpp.org/ftp/Specs/archive/38_series/38.201/\n","\n","def prepare_3gpp_documents():\n","    \"\"\"Process 3GPP documents from Google Drive or use sample documents if not found\"\"\"\n","    print(\"Processing 3GPP documents...\")\n","    from langchain.schema import Document\n","\n","    # Try to import required libraries\n","    try:\n","        import os\n","        from docx import Document as DocxDocument\n","        docx_available = True\n","    except ImportError:\n","        print(\"Warning: python-docx not available. Installing...\")\n","        !pip install python-docx\n","        import os\n","        from docx import Document as DocxDocument\n","        docx_available = True\n","\n","    documents = []\n","\n","    # Try to mount Google Drive if not already mounted\n","    try:\n","        from google.colab import drive\n","        drive_already_mounted = os.path.exists('/content/drive')\n","        if not drive_already_mounted:\n","            print(\"Mounting Google Drive...\")\n","            drive.mount('/content/drive')\n","\n","        # Try multiple possible paths where documents might be stored\n","        possible_paths = [\n","            \"/content/drive/MyDrive/airaChallenge/wireless_documents\",\n","            \"/content/drive/My Drive/airaChallenge/wireless_documents\",\n","            \"./wireless_documents\",\n","            \"/content/wireless_documents\"\n","        ]\n","\n","        found_docs = False\n","        docs_dir = None\n","\n","        for path in possible_paths:\n","            if os.path.exists(path):\n","                docs_dir = path\n","                found_docs = True\n","                print(f\"Found documents directory at: {docs_dir}\")\n","                break\n","\n","        if found_docs:\n","            # List all document files in the directory\n","            doc_count = 0\n","            for filename in os.listdir(docs_dir):\n","                if filename.endswith(\".doc\") or filename.endswith(\".docx\") or filename.endswith(\".txt\") or filename.endswith(\".pdf\"):\n","                    try:\n","                        filepath = os.path.join(docs_dir, filename)\n","\n","                        # Different handling based on file type\n","                        if filename.endswith(\".docx\"):\n","                            try:\n","                                doc = DocxDocument(filepath)\n","                                content = \"\\n\".join([para.text for para in doc.paragraphs if para.text])\n","                            except Exception as e:\n","                                print(f\"Error processing {filename} with docx: {e}\")\n","                                content = f\"Document {filename} content extraction failed\"\n","                        elif filename.endswith(\".txt\"):\n","                            with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:\n","                                content = f.read()\n","                        else:\n","                            # For .doc and .pdf, just note we found it\n","                            content = f\"Document {filename} found but format not fully supported for extraction.\"\n","\n","                        # Create a document object\n","                        documents.append(Document(\n","                            page_content=content,\n","                            metadata={\"source\": filepath, \"title\": filename}\n","                        ))\n","                        doc_count += 1\n","                        if doc_count % 10 == 0:  # Print status every 10 docs\n","                            print(f\"Processed {doc_count} documents so far...\")\n","                    except Exception as e:\n","                        print(f\"Error processing {filename}: {e}\")\n","\n","            print(f\"Successfully processed {doc_count} documents from {docs_dir}\")\n","        else:\n","            print(\"No documents directory found in common locations. Using sample documents.\")\n","            documents = create_sample_telecom_documents()\n","    except Exception as e:\n","        print(f\"Error accessing Google Drive: {e}\")\n","        print(\"Using sample telecom documents instead.\")\n","        documents = create_sample_telecom_documents()\n","\n","    # If no documents were processed, use sample documents\n","    if not documents:\n","        print(\"No documents were processed. Using sample telecom knowledge...\")\n","        documents = create_sample_telecom_documents()\n","\n","    print(f\"Total processed documents: {len(documents)}\")\n","    return documents\n","\n","def create_sample_telecom_documents():\n","    \"\"\"Create sample telecom documents with relevant 3GPP information\"\"\"\n","    documents = []\n","\n","    # Sample document from the 3GPP TS 38.201 you shared\n","    documents.append(Document(\n","        page_content=\"\"\"\n","        3GPP TS 38.201 V0.0.0 (2017-05)\n","        Technical Specification 3rd Generation Partnership Project;\n","        Technical Specification Group Radio Access Network;\n","        NR; Physical layer; General description (Release 15)\n","\n","        The present document describes a general description of the physical layer of 5G-NR.\n","\n","        1 Scope\n","        The present document describes a general description of the physical layer of 5G-NR.\n","\n","        2 References\n","        The following documents contain provisions which, through reference in this text, constitute provisions of the present document.\n","        [1] 3GPP TR 21.905: \"Vocabulary for 3GPP Specifications\"\n","        [2] 3GPP TS 38.202: \"NR; Services provided by the physical layer\"\n","        [3] 3GPP TS 38.211: \"NR; Physical channels and modulation\"\n","        [4] 3GPP TS 38.212: \"NR; Multiplexing and channel coding\"\n","        [5] 3GPP TS 38.xxx: \"NR; Physical layer procedures for control channels\"\n","        [6] 3GPP TS 38.yyy: \"NR; Physical layer procedures for data channels\"\n","        [7] 3GPP TS 38.215: \"NR; Physical layer measurements\"\n","        \"\"\",\n","        metadata={\"source\": \"sample_data\", \"title\": \"38.201-NR-Physical-layer-General-description.doc\"}\n","    ))\n","\n","    # Add more sample documents for key 5G concepts\n","    documents.append(Document(\n","        page_content=\"\"\"\n","        5G NR (New Radio) Key Concepts:\n","\n","        Frequency Ranges:\n","        - FR1 (Sub-6GHz): 450 MHz - 6000 MHz\n","        - FR2 (mmWave): 24.25 GHz - 52.6 GHz\n","\n","        Subcarrier Spacing Options:\n","        - 15 kHz, 30 kHz, 60 kHz, 120 kHz, 240 kHz\n","\n","        Numerology:\n","        - Based on subcarrier spacing\n","        - Î¼=0 (15 kHz), Î¼=1 (30 kHz), Î¼=2 (60 kHz), Î¼=3 (120 kHz), Î¼=4 (240 kHz)\n","\n","        Channel Coding:\n","        - LDPC (Low-Density Parity Check) for data channels\n","        - Polar codes for control channels\n","\n","        Multiple Access:\n","        - CP-OFDM (Cyclic Prefix Orthogonal Frequency Division Multiplexing)\n","\n","        MIMO Capabilities:\n","        - Massive MIMO\n","        - Multi-user MIMO\n","        - Beamforming techniques\n","        \"\"\",\n","        metadata={\"source\": \"sample_data\", \"title\": \"5G-NR-Key-Concepts.doc\"}\n","    ))\n","\n","    # Add document about 5G network architecture\n","    documents.append(Document(\n","        page_content=\"\"\"\n","        5G Network Architecture:\n","\n","        The 5G System architecture consists of:\n","        - UE (User Equipment)\n","        - NG-RAN (Next Generation Radio Access Network)\n","        - 5GC (5G Core Network)\n","\n","        Key Network Functions:\n","        - AMF (Access and Mobility Management Function)\n","        - SMF (Session Management Function)\n","        - UPF (User Plane Function)\n","        - PCF (Policy Control Function)\n","        - AUSF (Authentication Server Function)\n","        - UDM (Unified Data Management)\n","        - AF (Application Function)\n","        - NSSF (Network Slice Selection Function)\n","\n","        Service-Based Architecture (SBA):\n","        - Network functions communicate through service-based interfaces\n","        - RESTful APIs for communication\n","\n","        Network Slicing:\n","        - Multiple virtual networks on the same physical infrastructure\n","        - eMBB (Enhanced Mobile Broadband)\n","        - URLLC (Ultra-Reliable Low Latency Communications)\n","        - mMTC (Massive Machine Type Communications)\n","        \"\"\",\n","        metadata={\"source\": \"sample_data\", \"title\": \"5G-Network-Architecture.doc\"}\n","    ))\n","\n","    return documents"],"metadata":{"id":"-q8AsuzfuoQq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prepare_3gpp_documents_with_metadata():\n","    \"\"\"Enhanced version that preserves document structure and adds better metadata\"\"\"\n","    regular_docs = prepare_3gpp_documents()\n","\n","    # Enhance metadata for each document\n","    enhanced_docs = []\n","    for doc in regular_docs:\n","        # Extract document type from title if possible\n","        doc_type = \"general\"\n","        title = doc.metadata.get(\"title\", \"\")\n","\n","        if \"physical layer\" in title.lower():\n","            doc_type = \"physical_layer\"\n","        elif \"architecture\" in title.lower():\n","            doc_type = \"architecture\"\n","        elif \"key concepts\" in title.lower():\n","            doc_type = \"key_concepts\"\n","\n","        # Create enhanced metadata\n","        enhanced_metadata = {\n","            **doc.metadata,\n","            \"doc_type\": doc_type,\n","            \"source_type\": \"3GPP\"\n","        }\n","\n","        enhanced_docs.append(Document(\n","            page_content=doc.page_content,\n","            metadata=enhanced_metadata\n","        ))\n","\n","    return enhanced_docs"],"metadata":{"id":"xAK1FNSaFNnZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Add training data as documents\n","def convert_training_data_to_documents(train_data):\n","    \"\"\"Convert training data to Document format for RAG with improved metadata\"\"\"\n","    documents = []\n","\n","    for i, item in enumerate(train_data):\n","        # Create a document from each QA pair\n","        content = f\"Question: {item['question']}\\n\"\n","\n","        # Add options\n","        for option_key in sorted(k for k in item if k.startswith(\"option \")):\n","            content += f\"{option_key}: {item[option_key]}\\n\"\n","\n","        content += f\"Answer: {item['answer']}\"\n","\n","        content += \"\\n\\n---\\n\\n\"\n","\n","        content += f\"Category: {item['category']}\"\n","\n","        # Add explanation if available\n","        if 'explanation' in item:\n","            content += f\"\\nExplanation: {item['explanation']}\"\n","\n","        # Enhanced metadata\n","        metadata = {\n","            \"source\": \"training_data\",\n","            \"id\": i,   # Use category if available\n","        }\n","\n","        documents.append(Document(\n","            page_content=content,\n","            metadata=metadata\n","        ))\n","\n","    return documents"],"metadata":{"id":"Vh0NeG7yuoTx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. Process documents for RAG\n","def prepare_rag_documents(documents):\n","    \"\"\"Process documents for RAG with source-specific chunking strategy\"\"\"\n","    # Separate documents by source\n","    training_docs = [doc for doc in documents if doc.metadata.get(\"source\") == \"training_data\"]\n","    technical_docs = [doc for doc in documents if doc.metadata.get(\"source\") != \"training_data\"]\n","\n","    # Don't chunk training data - keep QA pairs intact\n","\n","    # Use larger chunks with more overlap for technical docs\n","    tech_splitter = RecursiveCharacterTextSplitter(\n","        chunk_size=500,  # Larger chunks for technical content\n","        chunk_overlap=50,  # More overlap to maintain context\n","        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n","    )\n","\n","    # Split only technical documents\n","    tech_chunks = tech_splitter.split_documents(technical_docs)\n","\n","    # Combine unchunked training data with chunked technical docs\n","    all_chunks = training_docs + tech_chunks\n","\n","    print(f\"Kept {len(training_docs)} training documents intact\")\n","    print(f\"Split {len(technical_docs)} technical documents into {len(tech_chunks)} chunks\")\n","    print(f\"Total documents for vector store: {len(all_chunks)}\")\n","\n","    return all_chunks"],"metadata":{"id":"JJnvcBtzuoWy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. Vector Store\n","def create_vector_store(documents, api_key=None):\n","    \"\"\"Create a vector store from documents using OpenAI embeddings\"\"\"\n","    print(\"Creating vector store...\")\n","\n","    # Initialize OpenAI embeddings\n","    embeddings = OpenAIEmbeddings(\n","        model=\"text-embedding-3-small\",  # or use \"text-embedding-ada-002\", \"text-embedding-3-small\" or \"text-embedding-3-large\" for newer models\n","    )\n","\n","    # Create vector store\n","    vectorstore = FAISS.from_documents(documents, embeddings)\n","    print(\"Vector store created successfully!\")\n","\n","    return vectorstore, embeddings"],"metadata":{"id":"JJ-A6yU_u-B6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 4. define inference_with_rag()\n","def inference_with_rag(data, model_path, vectorstore, batch_size=32, k=4):\n","    \"\"\"Use RAG-enhanced fine-tuned model with batching for inference\"\"\"\n","    import torch\n","    from peft import AutoPeftModelForCausalLM\n","    from transformers import AutoTokenizer\n","    import re\n","\n","    print(f\"Loading model from: {model_path}\")\n","\n","    # Use exactly the same loading approach as your fine-tuned version\n","    tokenizer = AutoTokenizer.from_pretrained(model_path)\n","    model = AutoPeftModelForCausalLM.from_pretrained(\n","        model_path,\n","        torch_dtype=torch.float16,\n","        device_map=\"auto\",\n","    )\n","\n","    # Create retriever from vectorstore\n","    retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})\n","\n","    predictions = {}\n","\n","    # Process in batches\n","    for i in range(0, len(data), batch_size):\n","        batch_data = data[i:i+batch_size]\n","        batch_prompts = []\n","        batch_ids = []\n","\n","        for question_id, question_data in enumerate(batch_data, start=i):\n","            question = question_data['question']\n","            options_text = \"\"\n","            for option_key in sorted(k for k in question_data if k.startswith(\"option \")):\n","                options_text += f\"{option_key}: {question_data[option_key]}\\n\"\n","\n","            # Get relevant context from vector store for this question\n","            context_docs = retriever.get_relevant_documents(question)\n","            context = \"\\n\\n\".join([doc.page_content for doc in context_docs])\n","\n","            # Create RAG-enhanced prompt that matches your fine-tuned style\n","            prompt = f\"\"\"You're a telemcommunications expert. Here's a multiple-choice question about telecommunications' {question_data['category'].lower() if question_data['category'] else ''}. Consider technical details carefully. Only respond with exactly one option without additional text, for example,\n","\n","Example:\n","Question: What does HTTPS stand for?\n","option 1: Hypertext Transfer Protocol Secure\n","option 2: Hypertext Transfer Protocol Standard\n","option 3: Hypertext Transfer Protocol System\n","option 4: Hypertext Transfer Protocol Specification\n","option 5: Hypertext Transfer Protocol\n","Answer: option 1\n","\n","Now, answer the question below in the same format:\n","Question: {question}\n","{options_text}[/INST]\"\"\"\n","\n","            batch_prompts.append(prompt)\n","            batch_ids.append(question_id)\n","\n","        # Tokenize batch\n","        inputs = tokenizer(batch_prompts, padding=True, padding_side='left', return_tensors=\"pt\").to(model.device)\n","\n","        # Generate for whole batch\n","        with torch.no_grad():\n","            outputs = model.generate(\n","                input_ids=inputs.input_ids,\n","                attention_mask=inputs.attention_mask,\n","                max_new_tokens=20,\n","                temperature=0.01,\n","                do_sample=False\n","            )\n","\n","        # Process batch outputs\n","        for output, q_id, prompt in zip(outputs, batch_ids, batch_prompts):\n","            generated_text = tokenizer.decode(output, skip_special_tokens=True)\n","\n","            # Remove the prompt from the generated text\n","            if prompt in generated_text:\n","                generated_text = generated_text[len(prompt):].strip().lower()\n","            else:\n","                generated_text = generated_text.strip().lower()\n","\n","            # Extract answer\n","            match = re.search(r\"option\\s*(\\d)\", generated_text)\n","            if not match:\n","                match = re.search(r\"^\\D*(\\d)\\D*$\", generated_text)\n","\n","            if match:\n","                option_number = match.group(1)\n","                predictions[q_id] = f\"option {option_number}\"\n","            else:\n","                predictions[q_id] = \"option 1\"  # default fallback\n","\n","    return predictions"],"metadata":{"id":"URdDQ-iTuoZg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","# k=4\n","# 1. Prepare training data documents (improved version)\n","train_documents = convert_training_data_to_documents(train_data)\n","\n","# 2. Prepare 3GPP documents (with enhanced metadata)\n","gpp_documents = prepare_3gpp_documents_with_metadata()\n","\n","# 3. Process documents using your existing function\n","combined_docs = prepare_rag_documents(train_documents + gpp_documents)\n","\n","# 4. Create vector store using your existing function\n","vectorstore, embeddings = create_vector_store(combined_docs)\n","\n","# 5. Use the exact model path from your test code\n","model_path = \"/content/telecom_finetuned/checkpoint-500\"\n","\n","# 6. Evaluate RAG-enhanced model\n","print(\"Evaluating RAG-enhanced model...\")\n","start = time.time()\n","rag_predictions = inference_with_rag(val_data, model_path, vectorstore)\n","end = time.time()\n","rag_runtime = end - start\n","rag_accuracy = evaluate_model(val_data, rag_predictions)\n","print(f\"RAG-enhanced model inference took {rag_runtime:.2f} seconds\")\n","print(f\"RAG-enhanced model accuracy: {rag_accuracy * 100:.2f}%\")\n","\n","{\n","    \"rag_accuracy\": rag_accuracy,\n","    \"rag_runtime\": rag_runtime,\n","}"],"metadata":{"id":"AJTXrqW2vCxk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1744533315951,"user_tz":420,"elapsed":2197143,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}},"outputId":"f66bbeaa-37cd-4421-986b-d5afbdfd3707"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing 3GPP documents...\n","Found documents directory at: /content/drive/MyDrive/airaChallenge/wireless_documents\n","Processed 10 documents so far...\n","Successfully processed 15 documents from /content/drive/MyDrive/airaChallenge/wireless_documents\n","Total processed documents: 15\n","Kept 6000 training documents intact\n","Split 15 technical documents into 15 chunks\n","Total documents for vector store: 6015\n","Creating vector store...\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-6-16051422e34c>:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n","  embeddings = OpenAIEmbeddings(\n"]},{"output_type":"stream","name":"stdout","text":["Vector store created successfully!\n","Evaluating RAG-enhanced model...\n","Loading model from: /content/telecom_finetuned/checkpoint-500\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-7-7d2d66ffa744>:37: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  context_docs = retriever.get_relevant_documents(question)\n"]},{"output_type":"stream","name":"stdout","text":["RAG-enhanced model inference took 2164.16 seconds\n","RAG-enhanced model accuracy: 70.30%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'rag_accuracy': 0.703, 'rag_runtime': 2164.1604523658752}"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["import time\n","# k=7\n","# 1. Prepare training data documents (improved version)\n","train_documents = convert_training_data_to_documents(train_data)\n","\n","# 2. Prepare 3GPP documents (with enhanced metadata)\n","gpp_documents = prepare_3gpp_documents_with_metadata()\n","\n","# 3. Process documents using your existing function\n","combined_docs = prepare_rag_documents(train_documents + gpp_documents)\n","\n","# 4. Create vector store using your existing function\n","vectorstore, embeddings = create_vector_store(combined_docs)\n","\n","# 5. Use the exact model path from your test code\n","model_path = \"/content/telecom_finetuned/checkpoint-500\"\n","\n","# 6. Evaluate RAG-enhanced model\n","print(\"Evaluating RAG-enhanced model...\")\n","start = time.time()\n","rag_predictions = inference_with_rag(val_data, model_path, vectorstore, k=7)\n","end = time.time()\n","rag_runtime = end - start\n","rag_accuracy = evaluate_model(val_data, rag_predictions)\n","print(f\"RAG-enhanced model inference took {rag_runtime:.2f} seconds\")\n","print(f\"RAG-enhanced model accuracy: {rag_accuracy * 100:.2f}%\")\n","\n","{\n","    \"rag_accuracy\": rag_accuracy,\n","    \"rag_runtime\": rag_runtime,\n","}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U7qn-icuZIs3","executionInfo":{"status":"ok","timestamp":1744537373567,"user_tz":420,"elapsed":261403,"user":{"displayName":"Shreya Sudan","userId":"04473196279885949377"}},"outputId":"da922b9f-32a4-4f23-d558-d5dec702b73d"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Processing 3GPP documents...\n","Found documents directory at: /content/drive/MyDrive/airaChallenge/wireless_documents\n","Processed 10 documents so far...\n","Successfully processed 15 documents from /content/drive/MyDrive/airaChallenge/wireless_documents\n","Total processed documents: 15\n","Kept 6000 training documents intact\n","Split 15 technical documents into 15 chunks\n","Total documents for vector store: 6015\n","Creating vector store...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-6-16051422e34c>:8: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n","  embeddings = OpenAIEmbeddings(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Vector store created successfully!\n","Evaluating RAG-enhanced model...\n","Loading model from: /content/telecom_finetuned/checkpoint-500\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-8-b319d1e474df>:37: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n","  context_docs = retriever.get_relevant_documents(question)\n"]},{"output_type":"stream","name":"stdout","text":["RAG-enhanced model inference took 2163.19 seconds\n","RAG-enhanced model accuracy: 70.30%\n"]},{"output_type":"execute_result","data":{"text/plain":["{'rag_accuracy': 0.703, 'rag_runtime': 2163.1861028671265}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["def implement_hybrid_solution():\n","    \"\"\"Try both with and without 3GPP docs to compare performance\"\"\"\n","    import time\n","    import gc\n","    import torch\n","\n","    # 1. Prepare training data documents (improved version)\n","    train_documents = convert_training_data_to_documents(train_data)\n","\n","    # 2. Prepare 3GPP documents (with enhanced metadata)\n","    gpp_documents = prepare_3gpp_documents_with_metadata()\n","\n","    # First test: Only training data\n","    print(\"\\n--- Testing with training data only ---\")\n","    train_only_docs = prepare_rag_documents(train_documents)\n","    train_only_vectorstore, _ = create_vector_store(train_only_docs)\n","\n","    # Evaluate\n","    model_path = \"/content/telecom_finetuned_model/checkpoint-400\"\n","    start = time.time()\n","    train_only_predictions = inference_with_rag(val_data, model_path, train_only_vectorstore)\n","    train_only_runtime = time.time() - start\n","    train_only_accuracy = evaluate_model(val_data, train_only_predictions)\n","\n","    del train_only_vectorstore\n","    gc.collect()\n","    torch.cuda.empty_cache()\n","\n","    # Second test: Both training and 3GPP data\n","    print(\"\\n--- Testing with training data + 3GPP documents ---\")\n","    combined_docs = prepare_rag_documents(train_documents + gpp_documents)\n","    combined_vectorstore, _ = create_vector_store(combined_docs)\n","\n","    # Evaluate\n","    start = time.time()\n","    combined_predictions = inference_with_rag(val_data, model_path, combined_vectorstore)\n","    combined_runtime = time.time() - start\n","    combined_accuracy = evaluate_model(val_data, combined_predictions)\n","\n","    # Report results\n","    print(\"\\n--- Results Comparison ---\")\n","    print(f\"Fine-tuned model only: {finetuned_accuracy * 100:.2f}%\")\n","    print(f\"RAG with training data only: {train_only_accuracy * 100:.2f}% (time: {train_only_runtime:.2f}s)\")\n","    print(f\"RAG with training + 3GPP data: {combined_accuracy * 100:.2f}% (time: {combined_runtime:.2f}s)\")\n","\n","    return {\n","        \"train_only_accuracy\": train_only_accuracy,\n","        \"combined_accuracy\": combined_accuracy,\n","        \"train_only_runtime\": train_only_runtime,\n","        \"combined_runtime\": combined_runtime\n","    }"],"metadata":{"id":"Z3xcE7d7-NsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rag_solution = implement_hybrid_solution()"],"metadata":{"id":"FiLOHxTk-Nuz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hP6xKAkay_d"},"source":["## Findings\n","\n","### Summary Statistics\n","|                      |    naive |   finetuned |       rag |\n","|:---------------------|---------:|------------:|----------:|\n","| accuracy             |   0.6325 |      0.7225 |    0.703  |\n","| runtime  (in seconds)| 170.745  |   1248.2    |  2163.18  |\n","\n","### Part A: Prompt Engineering and Inference Optimization\n","\n","For the Basic Inference Engine task, I focused on optimizing inference performance while maintaining accuracy on the TeleQnA dataset. The key challenge was to efficiently serve the `Llama 3.2-3B instruct` model in a production-ready setup.\n","\n","#### Model Serving Comparison\n","\n","I implemented and compared two popular model serving frameworks:\n","1. `vLLM`: Emerged as the superior option for this task. Key advantages included:\n","  - Efficient batch processing (32 prompts per batch)\n","  - Optimized CUDA kernels for faster inference\n","  - Continuous batching that significantly reduced latency\n","  - Proper memory management with PagedAttention\n","\n","2. `Ollama`: While easier to set up, it showed limitations:\n","  - Slower inference speeds despite multi-threading attempts\n","  - Less efficient memory management\n","  - Limited batch processing capabilities\n","\n","#### Prompt Engineering\n","\n","I experimented with several prompt configurations to improve accuracy:\n","\n","- Implemented few-shot examples with telecommunications-specific content\n","- Added explicit instructions for output formatting (responding with only the option number)\n","- Included clear delimiters between question components\n","Used structured examples to demonstrate the desired answer format\n","\n","The most effective prompt structure included:\n","```python\n","\"\"\"Answer the following multiple-choice question about telecommunications. Only respond with exactly one option (e.g., 'option 1', 'option 2', etc.) without any additional text.\n","\n","Example 1:\n","Question: What is the capital of France?\n","option 1: Berlin\n","option 2: Madrid\n","option 3: Paris\n","option 4: Rome\n","option 5: Oslo\n","Answer: option 3\n","\n","Example 2:\n","Question: What does HTTPS stand for?\n","option 1: Hypertext Transfer Protocol Secure\n","option 2: Hypertext Transfer Protocol Standard\n","option 3: Hypertext Transfer Protocol System\n","option 4: Hypertext Transfer Protocol Specification\n","option 5: Hypertext Transfer Protocol\n","Answer: option 1\n","\n","Now, answer the question below in the same format:\n","Question: {question}\n","\"\"\"\n","```\n","#### Parallelization Strategies\n","To optimize runtime performance, I implemented:\n","\n","- Batch processing of `32` questions at a time\n","- Asynchronous processing with proper concurrency management\n","- `ThreadPoolExecutor` for coordinating multiple inference requests\n","- Progress tracking with `tqdm` for monitoring batch processing\n","- `Regex`-based answer extraction for consistent response parsing\n","\n","This parallelized approach with `vLLM` achieved an accuracy of `63.25%` with a runtime of just `170.7` seconds for the entire validation set.\n","\n","---\n","\n","### Part B: Fine-Tuning the LLM\n","\n","#### Hyperparameter Optimization\n","\n","I systematically explored various hyperparameters for LoRA fine-tuning:\n","\n","**LoRA Configuration Experiments**\n","- Rank values: Tested `r=16` and `r=32`, with r=32 providing better performance\n","- Alpha settings: Set to 2x the rank value (`Î±=64` for `r=32`)\n","- Dropout rate: Tested `0.1`, `0.05`, and `0.01` as dropout rates. While `0.01` allowed for training time to be faster, it also led to overfitting to the training dataset, creating a considerable disparity between validation error and training error. I concluded that `0.05` was optimal as it balanced the tradeoff between runtime and performance of validation set.\n","- Target modules: Included query, key, value projection layers plus MLP components\n","\n","#### Training Dynamics\n","\n","- Step count analysis: Observed model convergence around 400-500 steps\n","- Overfitting detection: Monitored training vs. validation loss curves\n","- Epoch variation: Experimented with 3, 6, and 8 epochs, finding diminishing returns after 3\n","- Checkpoint evaluation: Implemented a function to evaluate all saved checkpoints to identify optimal model (`checkpoint-400`)\n","\n","#### Error Analysis\n","\n","**Category Error Rate**: Observed error rate by category to determine which categories are more likely to cause errors\n","\n","| Category                | Error Rate | Notes  |\n","|:------------------------|------------|-------:|\n","| Standards overview      |   0.27     | Moderate difficulty with technical specs |\n","| Research publications   |   0.49     | Highest error rate - complex citations |\n","| Research overview       |   0.28     | Struggled with research methodology |\n","| Standards specifications|  0.37      | Technical details caused confusion |\n","| Lexicon                 |   0.13     | Lowest error rate - definitional content |\n","\n","To address these category-specific errors, I modified the fine-tuning prompts to include category context:\n","```python\n","prompt = f\"You're a telecommunications expert. Here's a multiple-choice question about telecommunications' {item['category'].lower() if item['category'] else ''}. Consider technical details carefully. Only respond with exactly one option without additional text.\"\n","```\n","This category-aware prompting significantly improved performance on the most challenging categories, particularly for Standards specifications and Research overview.\n","\n","The fine-tuning process was executed using the `Unsloth` framework for efficiency, achieving a significant performance boost with an accuracy of `72.25%` on the validation set.\n","\n","---\n","\n","### Appendix: Retrieval-Augmented Generation (RAG) Implementation\n","\n","#### Implementation Details and Architecture\n","\n","I implemented a comprehensive RAG system to enhance the model's domain knowledge while maintaining inference efficiency:\n","\n","1. **Document Processing Pipeline**:\n","  - Developed source-specific document processors for training data and 3GPP technical documents\n","  - Added enhanced metadata tagging to improve retrieval context awareness\n","  - Preserved document structure and relationships through intelligent chunking\n","2. **Embedding Strategy**:\n","  - Tested three OpenAI embedding models: `text-embedding-ada-002`, `text-embedding-3-small`, and `text-embedding-3-large`\n","  - Found `text-embedding-3-small` provided the optimal balance of performance and efficiency given the dataset size (`~3.9`MB)\n","  - Larger models like `text-embedding-3-large` did not provide sufficient accuracy gains to justify the increased computation time\n","3. **Retrieval Optimization**:\n","  - Implemented FAISS vector store for efficient similarity search\n","  - Extensive $k$-parameter testing revealed non-linear performance relationships\n","4. **Prompt Enhancement**: Integrated retrieved context into the prompt structure\n","\n","#### Retrieval Parameter Experiments\n","\n","The retriever's $k$ parameter (number of documents retrieved per query) had significant impact on model performance:\n","\n","| k-Values| Accuracy| Runtime (s) | Notes   |\n","|:--------|---------|--------|-------------:|\n","| 3  |   0.6785     | 1873.44|Degraded performance vs. fine-tuned baseline|\n","| 4  |   0.703      | 2164.16|Optimal retrieval context size              |\n","| 7  |   0.703      | 2163.19|No additional gain with more documents      |\n","| 10 |  0.701       | 2560.29|Performance degradation with retrieval noise|\n","\n","\n","#### Chunking Strategy Analysis\n","A critical insight from my implementation was the importance of source-specific document chunking:\n","\n","1. **Training Data**: Preserved QA pairs as atomic units to maintain the integrity of question-answer relationships:\n","```python\n","# Separate documents by source\n","# Keep training data intact - no chunking\n","training_docs = [doc for doc in documents if doc.metadata.get(\"source\") == \"training_data\"]\n","# Don't chunk training data - keep QA pairs intact\n","```\n","2. **Technical Documents**: Implemented targeted chunking optimized for technical content:\n","```python\n","tech_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=500,  # Optimized chunk size for technical content\n","    chunk_overlap=50,  # Sufficient overlap to maintain context\n","    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",")\n","```\n","This hybrid approach preserved the semantic structure of each document type, significantly improving retrieval relevance compared to a one-size-fits-all chunking strategy.\n","\n","---\n","\n","### Performance Comparision Analysis\n","Comparing the three approaches reveals important trade-offs:\n","1. **Basic Inference (Naive)**:\n","  - Fastest runtime (170.7s) but lowest accuracy (63.25%)\n","  - Excellent for quick responses but limited domain knowledge\n","2. **Fine-tuned Model**:\n","  - Best accuracy (72.25%) with moderate runtime (1248.2s)\n","  - Fixed knowledge embedded in model weights\n","3. **RAG Implementation**:\n","  - Good accuracy (70.3%) with longest runtime (2163.19s)\n","  - More flexible knowledge base that can be updated without retraining\n","\n","The fine-tuned model outperformed RAG by approximately 2 percentage points while running nearly 2x faster. However, the RAG system offers key advantages in knowledge flexibility and extensibility that would be valuable in production scenarios where domain knowledge evolves rapidly.\n","\n","---\n","\n","### Conclusions and Production Recommendations\n","\n","Based on these experiments, I recommend:\n","\n","1. For static knowledge domains: Use the fine-tuned model for optimal performance-to-runtime ratio\n","2. For evolving domains: Use the RAG implementation with k=4 for balance of accuracy and efficiency\n","3. Consider a hybrid approach: Use the fine-tuned model as the base with RAG enhancement only for challenging questions or new domain knowledge areas\n","\n","This tiered implementation strategy would maximize both accuracy and computational efficiency in a production environment.\n","\n","---\n","\n","### Future Considerations and Improvements\n","\n","Based on the results and challenges encountered in this implementation, several promising avenues for improvement emerge:\n","\n","1. **Hybrid Retrieval System**:\n","  - Implement a combination of dense and sparse retrievers (BM25 + embedding-based) to capture both keyword matching and semantic similarity\n","  - Add a re-ranking layer using cross-encoders to further refine the retrieval results before passing to the LLM\n","2. **Inference Optimization**:\n","  - Implement caching at multiple levels (embedding cache, retrieval cache, and response cache) to improve repeat question performance\n","  - Explore quantization methods like INT4/INT8 to further reduce latency without significant accuracy drops\n","3. **Adaptive Retrieval System**\n","  - Develop a confidence-based system that dynamically adjusts the retrieval parameters (k value) based on question difficulty\n","  - Implement query expansion techniques to improve retrieval for questions with limited context\n","4. **Knowledge Base Expansion**:\n","- Incorporate additional telecommunications standards beyond 3GPP\n","- Add specialized knowledge sources for categories where the model showed weaknesses\n","\n","These improvements would provide promising directions for evolving this system into a more robust, accurate, and efficient production solution for telecommunications question answering."]},{"cell_type":"code","source":[],"metadata":{"id":"DvZSFIwe28iz"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c231d05884dd4448891da109c92a1978":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d04bab9b7a34730b77a0f9b487d56a1","IPY_MODEL_73635c92ad3e4ccb97a441ccbc4fa289","IPY_MODEL_11ae3bac72dc41be943800b7baaec8cb"],"layout":"IPY_MODEL_57ea75c7df4746dd86ff6fced04d3fb9"}},"7d04bab9b7a34730b77a0f9b487d56a1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abbae54eeb754795ad180d9b00ded787","placeholder":"â€‹","style":"IPY_MODEL_d9981acd226249c48fd812c8a7ef4496","value":"config.json:â€‡100%"}},"73635c92ad3e4ccb97a441ccbc4fa289":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc0908ebeba7418882158c04c4480f8f","max":878,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc7f7ce0e17b4aeca9fe80db8dbcde6f","value":878}},"11ae3bac72dc41be943800b7baaec8cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_311388ee80704bb6a52f536d9eda7965","placeholder":"â€‹","style":"IPY_MODEL_07a8a67bce734e31bc68df3f60f45e2b","value":"â€‡878/878â€‡[00:00&lt;00:00,â€‡83.8kB/s]"}},"57ea75c7df4746dd86ff6fced04d3fb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abbae54eeb754795ad180d9b00ded787":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9981acd226249c48fd812c8a7ef4496":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc0908ebeba7418882158c04c4480f8f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc7f7ce0e17b4aeca9fe80db8dbcde6f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"311388ee80704bb6a52f536d9eda7965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07a8a67bce734e31bc68df3f60f45e2b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ce6fd96a9894524939791be9b694ffd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e63c2b2dc6d848d5b5500b3b3e231580","IPY_MODEL_db56307a4d6441d29f805cc397e630e3","IPY_MODEL_42b0cfe825f64893aa288f949c679087"],"layout":"IPY_MODEL_c4e1465827fa4805b6d3602a9aaa32ab"}},"e63c2b2dc6d848d5b5500b3b3e231580":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcff5ed94fc84ff4b2b90baf370a04a0","placeholder":"â€‹","style":"IPY_MODEL_e4213e70f6cb430d95b03b29989a95e8","value":"tokenizer_config.json:â€‡100%"}},"db56307a4d6441d29f805cc397e630e3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a58c1ec487e3483ea1ade3c09fc58cf8","max":54528,"min":0,"orientation":"horizontal","style":"IPY_MODEL_98e580fde93f44dbba8392bad90fefad","value":54528}},"42b0cfe825f64893aa288f949c679087":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b365e257f8e4cc7ba49ee63a6ae548c","placeholder":"â€‹","style":"IPY_MODEL_b1e14a61012d4a2095aeab4f76cfd9d0","value":"â€‡54.5k/54.5kâ€‡[00:00&lt;00:00,â€‡1.77MB/s]"}},"c4e1465827fa4805b6d3602a9aaa32ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcff5ed94fc84ff4b2b90baf370a04a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4213e70f6cb430d95b03b29989a95e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a58c1ec487e3483ea1ade3c09fc58cf8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98e580fde93f44dbba8392bad90fefad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b365e257f8e4cc7ba49ee63a6ae548c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b1e14a61012d4a2095aeab4f76cfd9d0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ad12bb99eb4e22bb36ceea1384b427":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f6452231ee2140de97f51538993f50db","IPY_MODEL_a548bb8dcbf0457cbe1fa0c8f02035bf","IPY_MODEL_160c17a91a944cd8b506305849ed22f5"],"layout":"IPY_MODEL_9f22826c056c4490bbd1e659da06e4be"}},"f6452231ee2140de97f51538993f50db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_202582b9e7794ec18634cfd44cc4e98a","placeholder":"â€‹","style":"IPY_MODEL_dda30b1c6e494607a4d4fea869c59895","value":"tokenizer.json:â€‡100%"}},"a548bb8dcbf0457cbe1fa0c8f02035bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_12e2a15a2d2c436fb5d5f877656936af","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d86d9a3686fe4752b5932242ea3f13d3","value":9085657}},"160c17a91a944cd8b506305849ed22f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7586ac91ca8b4330a855768d39c05899","placeholder":"â€‹","style":"IPY_MODEL_51c12655f8ea49179348f0e9b7c62a9e","value":"â€‡9.09M/9.09Mâ€‡[00:00&lt;00:00,â€‡15.0MB/s]"}},"9f22826c056c4490bbd1e659da06e4be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"202582b9e7794ec18634cfd44cc4e98a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dda30b1c6e494607a4d4fea869c59895":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12e2a15a2d2c436fb5d5f877656936af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d86d9a3686fe4752b5932242ea3f13d3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7586ac91ca8b4330a855768d39c05899":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51c12655f8ea49179348f0e9b7c62a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"935ac7181ba04da681ea57bdb0728b93":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_77ead0c16a504ac0bc532a8e0f918e84","IPY_MODEL_c1489a6d153647f997d4a41df4021a48","IPY_MODEL_20fa0c26c2844b3cbfbbfc635865b557"],"layout":"IPY_MODEL_b089056ba32e4e3c8e5d1277b0c022e4"}},"77ead0c16a504ac0bc532a8e0f918e84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_475051f8a52e4f9884a3df46522e2986","placeholder":"â€‹","style":"IPY_MODEL_d2d9111f88e74cd3a2e5265aac820a5e","value":"special_tokens_map.json:â€‡100%"}},"c1489a6d153647f997d4a41df4021a48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_af3a46408a634f3f929f7565e8bc3aa9","max":296,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cf72160633a845cf87098b25f4fa6440","value":296}},"20fa0c26c2844b3cbfbbfc635865b557":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4428a476571340f8b24b94239da541bf","placeholder":"â€‹","style":"IPY_MODEL_5f93642370c64d98a1cf7add21240cec","value":"â€‡296/296â€‡[00:00&lt;00:00,â€‡15.1kB/s]"}},"b089056ba32e4e3c8e5d1277b0c022e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"475051f8a52e4f9884a3df46522e2986":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2d9111f88e74cd3a2e5265aac820a5e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af3a46408a634f3f929f7565e8bc3aa9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf72160633a845cf87098b25f4fa6440":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4428a476571340f8b24b94239da541bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f93642370c64d98a1cf7add21240cec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9d7bd86a216496181d9367e1293ec3d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db374ace05344701a9ea4dca361a163d","IPY_MODEL_b01e72ea841b414fb13199d33e230115","IPY_MODEL_44659abb45ab4b159b27dcaade0b22d2"],"layout":"IPY_MODEL_0acf2375d0d840e1bdc15901ad40d839"}},"db374ace05344701a9ea4dca361a163d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a31b1ec251c4b61bb8d5147e099b177","placeholder":"â€‹","style":"IPY_MODEL_7832711e51654513b43e6a1e54d0d391","value":"generation_config.json:â€‡100%"}},"b01e72ea841b414fb13199d33e230115":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c37d45a0c3e24df8b80d4c974cdd491c","max":189,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66b4a5aa97d14c54b620d93a2f5a9094","value":189}},"44659abb45ab4b159b27dcaade0b22d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd07d6ac9474c0f89435f6dfdbf80c6","placeholder":"â€‹","style":"IPY_MODEL_4cc5c44336e54af5a8e62d031c28b430","value":"â€‡189/189â€‡[00:00&lt;00:00,â€‡12.8kB/s]"}},"0acf2375d0d840e1bdc15901ad40d839":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a31b1ec251c4b61bb8d5147e099b177":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7832711e51654513b43e6a1e54d0d391":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c37d45a0c3e24df8b80d4c974cdd491c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66b4a5aa97d14c54b620d93a2f5a9094":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fd07d6ac9474c0f89435f6dfdbf80c6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cc5c44336e54af5a8e62d031c28b430":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3fa7008e51f74f6298815b9ac1ce8d8c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0544b754716f435c8cced9005c824b58","IPY_MODEL_5e1f2328e6b048699490c84824c40f79","IPY_MODEL_a9df74f844f4495e91db3bc72e37d77c"],"layout":"IPY_MODEL_4a87596cf20f4e2199000c04c370fd67"}},"0544b754716f435c8cced9005c824b58":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae31d11bbbd447c887c85393b7bf99ef","placeholder":"â€‹","style":"IPY_MODEL_c8762824da8247d48144c42ce3edf810","value":"model-00001-of-00002.safetensors:â€‡100%"}},"5e1f2328e6b048699490c84824c40f79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1d6b769e33745e49abf540d66195e2a","max":4965799096,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9922cb39f7c24f1a9eba996d88747d42","value":4965798623}},"a9df74f844f4495e91db3bc72e37d77c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_004c5194d0cc4109a6bfd4635fe53333","placeholder":"â€‹","style":"IPY_MODEL_0309b9a81fce45a382ad859a1773f67f","value":"â€‡4.97G/4.97Gâ€‡[02:07&lt;00:00,â€‡36.1MB/s]"}},"4a87596cf20f4e2199000c04c370fd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae31d11bbbd447c887c85393b7bf99ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8762824da8247d48144c42ce3edf810":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1d6b769e33745e49abf540d66195e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9922cb39f7c24f1a9eba996d88747d42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"004c5194d0cc4109a6bfd4635fe53333":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0309b9a81fce45a382ad859a1773f67f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92367e10b8f4480ea3783d6a4e8d1712":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1218d3c5b8c4f0b99b8940628fee6c6","IPY_MODEL_6a3c300867cc42c2972e6e2a7b477f8d","IPY_MODEL_be71bec5738f482cb4d6771a3cf065f7"],"layout":"IPY_MODEL_0e0e023fed06488b8cebdd9acfaca824"}},"c1218d3c5b8c4f0b99b8940628fee6c6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8552bb965e1341d6ba0af5fdf9b82690","placeholder":"â€‹","style":"IPY_MODEL_dd28c881d58b4fafae241e76b208bba7","value":"model-00002-of-00002.safetensors:â€‡100%"}},"6a3c300867cc42c2972e6e2a7b477f8d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_e84d256ab1864e748fae4964209810a0","max":1459729952,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26117f210199479cac8924c474d6b20d","value":1459729813}},"be71bec5738f482cb4d6771a3cf065f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_680742a695f8448bac3b4fbf51e87e08","placeholder":"â€‹","style":"IPY_MODEL_f41e8de86ff64ba796dc5d5db6327500","value":"â€‡1.46G/1.46Gâ€‡[00:36&lt;00:00,â€‡163MB/s]"}},"0e0e023fed06488b8cebdd9acfaca824":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8552bb965e1341d6ba0af5fdf9b82690":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd28c881d58b4fafae241e76b208bba7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e84d256ab1864e748fae4964209810a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26117f210199479cac8924c474d6b20d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"680742a695f8448bac3b4fbf51e87e08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f41e8de86ff64ba796dc5d5db6327500":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5feeb673a91f4892bbae7f6ef8fc5797":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a2a0fbdf72af4130afd8fcce081062a2","IPY_MODEL_3e3a66ba312a4567b538ccf6d54728e0","IPY_MODEL_c80348edb6c24a3496777590dd9a5e18"],"layout":"IPY_MODEL_344786bc71e243f4a76923824c57a436"}},"a2a0fbdf72af4130afd8fcce081062a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a34feeab6b064d0fb08369f0b5bf80fd","placeholder":"â€‹","style":"IPY_MODEL_5a430d4c37c8499fbc035b1b561f3d08","value":"model.safetensors.index.json:â€‡100%"}},"3e3a66ba312a4567b538ccf6d54728e0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee4bf036be504cafb07f988bd3a9515a","max":20919,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aaf8b00e94d641c18f283a5b04186004","value":20919}},"c80348edb6c24a3496777590dd9a5e18":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a604874cf904f0fae11fc2f91b1fdca","placeholder":"â€‹","style":"IPY_MODEL_eed1a7d9755f47339d1061a762d20a1f","value":"â€‡20.9k/20.9kâ€‡[00:00&lt;00:00,â€‡1.89MB/s]"}},"344786bc71e243f4a76923824c57a436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a34feeab6b064d0fb08369f0b5bf80fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a430d4c37c8499fbc035b1b561f3d08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee4bf036be504cafb07f988bd3a9515a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaf8b00e94d641c18f283a5b04186004":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9a604874cf904f0fae11fc2f91b1fdca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eed1a7d9755f47339d1061a762d20a1f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d44bf4153acc4616b5d1504b4fbea656":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ba9cabfa912b4ba6a234b82a488fc218","IPY_MODEL_c5477ea326c74df090a784e61fad840a","IPY_MODEL_fd77cb6cb29545f9a2872fb31079862e"],"layout":"IPY_MODEL_11ea231455f84f46801af1a529f2f1f9"}},"ba9cabfa912b4ba6a234b82a488fc218":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7727a6694f8846a1a343c2cb5e23120b","placeholder":"â€‹","style":"IPY_MODEL_8eaebddecc024b32988878e195194908","value":""}},"c5477ea326c74df090a784e61fad840a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07f544fa8eae42a98eb5a51a61f3ce10","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b7762ed743be47d8acca23d584f74c9b","value":2}},"fd77cb6cb29545f9a2872fb31079862e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6865447435641ea808e3eca4d0dd878","placeholder":"â€‹","style":"IPY_MODEL_79a31db2781e42faa8d42026e59a1703","value":"Loadingâ€‡safetensorsâ€‡checkpointâ€‡shards:â€‡100%â€‡Completedâ€‡|â€‡2/2â€‡[00:31&lt;00:00,â€‡14.28s/it]\n"}},"11ea231455f84f46801af1a529f2f1f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7727a6694f8846a1a343c2cb5e23120b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eaebddecc024b32988878e195194908":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07f544fa8eae42a98eb5a51a61f3ce10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7762ed743be47d8acca23d584f74c9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6865447435641ea808e3eca4d0dd878":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79a31db2781e42faa8d42026e59a1703":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2a20ed3b99346ffa9c6eb3cd68c3997":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_120a2365cdac4e8eb4b0cf9a0cb78f8e"}},"9fb1cbc4e2fb4d13aa6005485992f10b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b3b57540193c458086be59d696f63777","placeholder":"â€‹","style":"IPY_MODEL_90c64196215640adbe79e8e9720bd1a3","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"7426488d31f94acab057209af4353c39":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_eaaa8bcd2164412ebaeaf0e85f08c51c","placeholder":"â€‹","style":"IPY_MODEL_16cb1309b0674bdc8158fb0ec4e5e23f","value":""}},"db756b55b90a48558fb57d44be3d37f2":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_121b5803f96e43bd847f3656b5c8df9e","style":"IPY_MODEL_4a7cb05397b84d808eee8928cca7dd7d","value":true}},"399c325105cd47d189cccf4783d9f786":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_f75c7fa37806428e8d4b601573682c72","style":"IPY_MODEL_47b67ac0fa6c4c75ac3a689b9b927610","tooltip":""}},"27c3c39e09a54fe8b552afc499985afd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4570a8aaa7884b7e86f0b76508a18845","placeholder":"â€‹","style":"IPY_MODEL_a0376691e4f8403d936d8c4671ede9e8","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"120a2365cdac4e8eb4b0cf9a0cb78f8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"b3b57540193c458086be59d696f63777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90c64196215640adbe79e8e9720bd1a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaaa8bcd2164412ebaeaf0e85f08c51c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16cb1309b0674bdc8158fb0ec4e5e23f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"121b5803f96e43bd847f3656b5c8df9e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a7cb05397b84d808eee8928cca7dd7d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f75c7fa37806428e8d4b601573682c72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"47b67ac0fa6c4c75ac3a689b9b927610":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"4570a8aaa7884b7e86f0b76508a18845":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0376691e4f8403d936d8c4671ede9e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef679091f8f94386b51b266cfc569725":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6373849f26f49758a0e8c4a3f301e28","placeholder":"â€‹","style":"IPY_MODEL_d1bc5bcae274456ca806463f6a9a5c6b","value":"Connecting..."}},"f6373849f26f49758a0e8c4a3f301e28":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1bc5bcae274456ca806463f6a9a5c6b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5518389e9654da7937dba7e4531e699":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2fad272eb1024e0596b9ad7421727aa4","IPY_MODEL_ee4262acbb294dcfa8f7b15b21388d91","IPY_MODEL_09db201301984f8fa24ab0477588cc0d"],"layout":"IPY_MODEL_b37a4d2d5cf14fc4becbea735e171fa6"}},"2fad272eb1024e0596b9ad7421727aa4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d72002bac1f42dcba8fa738ff9e7882","placeholder":"â€‹","style":"IPY_MODEL_18ded8b4b5484a64876e2a2def7b2fce","value":"Convertingâ€‡trainâ€‡datasetâ€‡toâ€‡ChatMLâ€‡(num_proc=2):â€‡100%"}},"ee4262acbb294dcfa8f7b15b21388d91":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4db2baa2a09e451e8895f9d2b5756b03","max":6000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_85c3c074cf1641b1960bbde67bf8c3e4","value":6000}},"09db201301984f8fa24ab0477588cc0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b76458de4ed74bf7a71de5650085311d","placeholder":"â€‹","style":"IPY_MODEL_388cff1130844d3cbb3cda1cca752d80","value":"â€‡6000/6000â€‡[00:00&lt;00:00,â€‡20510.01â€‡examples/s]"}},"b37a4d2d5cf14fc4becbea735e171fa6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6d72002bac1f42dcba8fa738ff9e7882":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18ded8b4b5484a64876e2a2def7b2fce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4db2baa2a09e451e8895f9d2b5756b03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85c3c074cf1641b1960bbde67bf8c3e4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b76458de4ed74bf7a71de5650085311d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"388cff1130844d3cbb3cda1cca752d80":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09b3202b094742c59403cf75dac3646a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94e0aeeb45a34960b059032a133c26db","IPY_MODEL_79f0734c755e43afb2efb63d63afc3c2","IPY_MODEL_496bf490032649fbba31596805954d71"],"layout":"IPY_MODEL_30eed52c15504319a7d37614e5d7f4c3"}},"94e0aeeb45a34960b059032a133c26db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa50bf91414d45c5a685282bfb602003","placeholder":"â€‹","style":"IPY_MODEL_452ddf2fb25b4094a36515873792f201","value":"Applyingâ€‡chatâ€‡templateâ€‡toâ€‡trainâ€‡datasetâ€‡(num_proc=2):â€‡100%"}},"79f0734c755e43afb2efb63d63afc3c2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c85e6d10601f4864a17a026274da74fd","max":6000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1be71da38d9b473583c3b3ed3fafaebf","value":6000}},"496bf490032649fbba31596805954d71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4391015177e54ebc81d30618dfd48f33","placeholder":"â€‹","style":"IPY_MODEL_d14650774b7c488d893732b06f107c9b","value":"â€‡6000/6000â€‡[00:02&lt;00:00,â€‡3217.25â€‡examples/s]"}},"30eed52c15504319a7d37614e5d7f4c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa50bf91414d45c5a685282bfb602003":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"452ddf2fb25b4094a36515873792f201":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c85e6d10601f4864a17a026274da74fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1be71da38d9b473583c3b3ed3fafaebf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4391015177e54ebc81d30618dfd48f33":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d14650774b7c488d893732b06f107c9b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05e45988d5c74d6e8ebf4b144bac9931":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ceb69a1593ca49b99f95ca50c7d40bda","IPY_MODEL_85efe3f237e94b409b78604a70ce97b0","IPY_MODEL_bafd32ec9d944a0ebc869a29d4e10377"],"layout":"IPY_MODEL_d664cc6582f5419ba98f1f1a63d55608"}},"ceb69a1593ca49b99f95ca50c7d40bda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46861028e68447258096b5e72042b871","placeholder":"â€‹","style":"IPY_MODEL_ed51a329b72c492aa69ad7dca4200aa7","value":"Tokenizingâ€‡trainâ€‡datasetâ€‡(num_proc=2):â€‡100%"}},"85efe3f237e94b409b78604a70ce97b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa077d1d8a6b40428eae645ad074b917","max":6000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a71ede9afff45a9b139845652ae6e34","value":6000}},"bafd32ec9d944a0ebc869a29d4e10377":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c252e20995347d9aebcef1fe1430714","placeholder":"â€‹","style":"IPY_MODEL_98ba359f572245e6b57ab6554fe248c6","value":"â€‡6000/6000â€‡[00:05&lt;00:00,â€‡898.71â€‡examples/s]"}},"d664cc6582f5419ba98f1f1a63d55608":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46861028e68447258096b5e72042b871":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed51a329b72c492aa69ad7dca4200aa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa077d1d8a6b40428eae645ad074b917":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a71ede9afff45a9b139845652ae6e34":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9c252e20995347d9aebcef1fe1430714":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"98ba359f572245e6b57ab6554fe248c6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8bd9658450284addaf830625f0ef5a99":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":[],"layout":"IPY_MODEL_3e1499e4de7144a9a003f1595c29558c"}},"ec5a9c52ebed44d19c4768bc993d235b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_452be979cea943df8003074fb2cfd05d","placeholder":"â€‹","style":"IPY_MODEL_7b74ccbe5bcb43469107da64123735a3","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"7d981d02638f45cfb9279c6efacab2c1":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_348c76d990c34700806e11a99718cd43","placeholder":"â€‹","style":"IPY_MODEL_5bba2e6a80ea4ef2b0bb119a9984681e","value":""}},"66005074b14a4f7bb56212116da60b53":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_7c7810cf168342beb217cdf184e2a8ac","style":"IPY_MODEL_3d51d1a97f804c2f8521d8602c023555","value":true}},"cff375b4bed3483c8c6f0926f5b46d92":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_14d738b7e0c048b68f80b8db380784ea","style":"IPY_MODEL_4c8345a67d144a648b2cfe7fcff38825","tooltip":""}},"5dff4f6edde34097ad16a42ee4b1c974":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e3f0014ed4548beb2abc2ed08355896","placeholder":"â€‹","style":"IPY_MODEL_36c568fec7ac4de9ba5e59c2fc02ebbc","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"3e1499e4de7144a9a003f1595c29558c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"452be979cea943df8003074fb2cfd05d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b74ccbe5bcb43469107da64123735a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"348c76d990c34700806e11a99718cd43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bba2e6a80ea4ef2b0bb119a9984681e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c7810cf168342beb217cdf184e2a8ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d51d1a97f804c2f8521d8602c023555":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14d738b7e0c048b68f80b8db380784ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c8345a67d144a648b2cfe7fcff38825":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"6e3f0014ed4548beb2abc2ed08355896":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36c568fec7ac4de9ba5e59c2fc02ebbc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05ded2dc455d481586976aaf9394c2c5":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3ae97b9ec18e4349b6e810de752cd173","placeholder":"â€‹","style":"IPY_MODEL_e66e6b9b55de4db88177c43609fcddaa","value":"Connecting..."}},"3ae97b9ec18e4349b6e810de752cd173":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e66e6b9b55de4db88177c43609fcddaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}